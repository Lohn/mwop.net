<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/">
  <channel>
    <title>Blog Entries :: phly, boy, phly</title>
    <description>Blog Entries :: phly, boy, phly</description>
    <pubDate>Wed, 26 Mar 2014 20:30:00 +0000</pubDate>
    <generator>Zend_Feed_Writer 2 (http://framework.zend.com)</generator>
    <link>http://mwop.net/blog.html</link>
    <atom:link rel="self" type="application/rss+xml" href="http://mwop.net/blog-rss.xml"/>
    <item>
      <title>Apigility: Using RPC with HAL</title>
      <pubDate>Wed, 26 Mar 2014 20:30:00 +0000</pubDate>
      <link>http://mwop.net/blog/2014-03-26-apigility-rpc-with-hal.html</link>
      <guid>http://mwop.net/blog/2014-03-26-apigility-rpc-with-hal.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    A few days ago, we <a href="http://bit.ly/ag-1-beta1">released our first beta of Apigility</a>.
    We've started our documentation effort now, and one question has arisen a few times that I
    want to address: How can you use Hypermedia Application Language (HAL) in RPC services?
</p><h2>HAL?</h2>

<p>
    <a href="http://tools.ietf.org/html/draft-kelly-json-hal-06">Hypermedia Application Language</a>
    is an IETF proposal for how to represent resources and their relations within APIs. Technically,
    it provides two mediatypes, <code>application/hal+json</code> and <code>application/hal+xml</code>;
    however, Apigility only provides the JSON variant.
</p>

<p>
    The important things to know about HAL are:
</p>

<ul>
    <li>
        <p>
            It provides a standard way of describing relational links. All relational
            links are under a <code>_links</code> property of the resource. That property
            is an object. Each property of that object is a link relation; the value of
            each link relation is an object (or array of such objects) describing the link
            that must minimally contain an <code>href</code> proerty. The link object
            itself can contain some additional metadata, such as a mediatype, a name
            (useful for differentiating between multiple link objects assigned to the same
            relation).
        </p>

        <p>
            While not required, the specification recommends resources contain a "self"
            relational link, indicating the canonical location for the resource. This
            is particularly useful when we consider embedding (the next topic).
        </p>

        <p>
            Sound hard? It's not:
        </p>

        <div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {
            "href": "/blog/2014-03-26-apigility-rpc-with-hal"
        }
    }
}
        </code></pre></div>
    </li>

    <li>
        <p>
            Besides link relations, HAL also provides a standard way of describing
            <em>embedded resources</em>. An embedded resource is any other resource
            you can address via your API, and, as such, would be structured as a HAL
            resource -- in other words, it would have a <code>_links</code> property
            with relational links. Essentially, any property of the resource you're
            returning that can itself be addressed via the URI must be <em>embedded</em>
            in the resource. This is done via the property <code>_embedded</code>.
        </p>

        <p>
            Like <code>_links</code>, <code>_embedded</code> is an object. Each key in the
            object is the local name by which the resource refers to the embedded resource.
            The value of such keys can either be HAL resources or <em>arrays</em> of HAL
            resources; in fact, this is how <em>collections</em> are represented in HAL!
        </p>

        <p>
            As examples:
        </p>

        <div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {
            "href": "/blog/2014-03-26-apigility-rpc-with-hal"
        }
    },
    "_embedded": {
        "author": {
            "_links": {
                "self": {
                    "href": "/blog/author/matthew"
                }
            },
            "id": "matthew",
            "name": "Matthew Weier O'Phinney",
            "url": "http://mwop.net"
        },
        "tags": [
            {
                "_links": {
                    "self": {
                        "href": "/blog/tag/php"
                    }
                },
                "id": "php"
            },
            {
                "_links": {
                    "self": {
                        "href": "/blog/tag/rest"
                    }
                },
                "id": "rest"
            }
        ]
    }
}
        </code></pre></div>

        <p>
            The example above shows two embedded resources. The first is the author;
            the second, a collection of tags. Note that <em>every</em> object
            under <code>_embedded</code> is a HAL object!
        </p>

        <p>
            You can go quite far with this -- you can also have embedded resources
            inside your embedded resources, arbitrarily deep.
        </p>
    </li>
</ul>

<h2>RPC?</h2>

<p>
    RPC stands for Remote Procedure Call, and, when describing a web API, is 
    usually used to describe a web service that publishes multiple method calls 
    at a single URI using only <code>POST</code>; XML-RPC and SOAP are the
    usual suspects.
</p>

<p>
    In Apigility, we use the term RPC in a much looser sense; we use it to describe
    one-off services: actions like "authenticate," or "notify," or "register" 
    would all make sense here. They are actions that usually only need to respond
    to a single HTTP method, and which may or may not describe a "thing", which
    is what we usually consider a "resource" when discussing REST terminology.
</p>

<p>
    That said: what if what we want to return from the RPC call <em>are</em> REST
    resources?
</p>

<h2>Returning HAL from RPC Services</h2>

<p>
    In order to return HAL from RPC services, we need to understand (a) how 
    Content Negotiation works, and (b) what needs to be returned in order for the
    HAL renderer to be able to create a representation.
</p>

<p>
    For purposes of this example, I'm positing a <code>RegisterController</code> as
    an RPC service that, on success, is returning a <code>User</code> object 
    that I want rendered as a HAL resource.
</p>

<p>
    The <a href="https://github.com/zfcampus/zf-content-negotiation">zf-content-negotiation</a>
    module takes care of content negotiation for Apigility. It introspects the <code>Accept</code>
    header in order to determine if we can return a representation, and then, if it can, will
    cast any <code>ZF\ContentNegotiation\ViewModel</code> returned from a controller to the
    appropriate view model for the representation. From there, a renderer will pick up the view
    model and do what needs to be done.
</p>

<p>
    So, the first thing we have to do is return <code>ZF\ContentNegotiation\ViewModel</code>
    instances from our controller.
</p>

<div class="example"><pre><code language="php">
use Zend\Mvc\Controller\AbstractActionController;
use ZF\ContentNegotiation\ViewModel;

class RegisterController extends AbstractActionController
{
    public function registerAction()
    {
        /* ... do some work ... get a user ... */
        return new ViewModel(array('user' => $user));
    }
}
</code></pre></div>

<p>
    The <a href="https://github.com/zfcampus/zf-hal">zf-hal</a> module in Apigility
    creates the actual HAL representations. <code>zf-hal</code> looks for a "payload" variable in
    the view model, and expects that value to be either a <code>ZF\Hal\Entity</code>
    (single item) or <code>ZF\Hal\Collection</code>. When creating an <code>Entity</code>
    object, you need the object being represented, as well as the identifier. 
    So, let's update our return value.
</p>

<div class="example"><pre><code language="php">
use Zend\Mvc\Controller\AbstractActionController;
use ZF\ContentNegotiation\ViewModel;
use ZF\Hal\Entity;

class RegisterController extends AbstractActionController
{
    public function registerAction()
    {
        /* ... do some work
         * ... get a $user
         * ... assume we have also now have an $id
         */
        return new ViewModel(array('payload' => array(
            'user' => new Entity($user, $id),
        )));
    }
}
</code></pre></div>

<p>
    <code>zf-hal</code> contains what's called a "metadata map". This is a map of classes to
    information on how <code>zf-hal</code> should render them: what route to use, what additional
    relational links to inject, how to serialize the object, what field represents
    the identifier, etc.
</p>

<p>
    In most cases, you will have likely already defined a REST service for the
    resource you want to return from the RPC service, in which case you will
    be done. However, if you want, you can go in and manually configure
    the metadata map in your API module's <code>config/module.config.php</code>
    file:
</p>

<div class="example"><pre><code language="php">
return array(
    /* ... */
    'zf-hal' => array(
        'metadata_map' => array(
            'User' => array(
                'route_name' => 'api.rest.user',
                'entity_identifier_name' => 'username',
                'route_identifier_name' => 'user_id',
                'hydrator' => 'Zend\Stdlib\Hydrator\ObjectProperty',
            ),
        ),
    ),
);
</code></pre></div>

<p>
    Finally, we need to make sure that the service is configured to actually return
    HAL. We can do this in the admin if we want. Find the "Content Negotiation" section
    of the admin, and the "Content Negotiation Selector" item, and set that to "HalJson";
    don't forget to save! Alternately, you can do this manually in the API module's 
    <code>config/module.config.php</code> file, under the <code>zf-content-negotiation</code>
    section:
</p>

<div class="example"><pre><code language="php">
return array(
    /* ... */
    'zf-content-negotiation' => array(
        'controllers' => array(
            /* ... */
            'RegisterController' => 'HalJson',
        ),
        /* ... */
    ),
);
</code></pre></div>

<p>
    Once your changes are complete, when you make a successful request to the URI
    for your "register" RPC service, you'll receive a HAL response pointing to the
    canonical URI for the user resource created!
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>A Bower Primer</title>
      <pubDate>Tue, 03 Dec 2013 15:50:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-12-03-bower-primer.html</link>
      <guid>http://mwop.net/blog/2013-12-03-bower-primer.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    Recently, I've been doing a fair bit of frontend development with my team 
    as we've worked on the <a href="http://apigility.org/">Apigility</a> admin.
    This has meant working with a variety of both JavaScript and CSS
    libraries, often trying something out only to toss it out again later.
    Working with frontend libraries has been quite a hassle, due to a combination
    of discovery, installation issues, and build issues (minimization, primarily).
    I figured there must a better way.
</p><h2>Background</h2>

<p>
    Until recently, discovery of JS and CSS libraries has gone something like this:
</p>

<ol>
    <li>Search for functionality via Google</li>
    <li>Generally find a solution on StackOverflow</li>
    <li>Discover said solution relies on a third-party library</li>
    <li>Google for said library</li>
    <li>Generally find said library on GitHub</li>
    <li>Clone the library locally</li>
    <li>Either build the final assets, or try and locate them in the repo</li>
    <li>Minimize the assets</li>
    <li>Copy the assets into the project</li>
</ol>

<p>
    Frontend development sucks.
</p>

<p>
    Then I started noticing these files called <code>.bowerrc</code> and 
    <code>bower.json</code> in many of the aforementioned libraries, and also
    that <a href="http://ralphschindler.com/">Ralph</a> had put some inside our
    Apigility skeleton. I got curious as to what this "bower" might be.
</p>

<h2>Bower: Package management for the web</h2>

<p>
    Essentially, <a href="http://bower.io/">Bower</a> is, to use the project's
    words, "a package manager for the web." Written in JavaScript, and running
    on <a href="http://nodejs.org/">node.js</a>, it is to frontend assets what
    <a href="https://npmjs.org/">npm</a> is to node, or <a href="https://getcomposer.org">Composer</a> 
    is to PHP. It allows you to define what assets you need in your application,
    including the versions, and then install them. If any of those assets have
    other dependencies, those, too, will be installed.
</p>

<p>
    Later, you can update the dependencies, add or remove dependencies, and more.
</p>

<p>
    On top of that, bower allows you to <em>search</em> for packages, which
    essentially allows you to eliminate most of the steps 4 and on in my list
    above.
</p>

<h2>A Bower Primer</h2>

<p>So, how do you use bower?</p>

<p>
    In my experience, which is not extensive by any stretch, the usage is like this:
</p>

<ol>
    <li>Search for functionality via Google</li>
    <li>Generally find a solution on StackOverflow</li>
    <li>Discover said solution relies on a third-party library</li>
    <li>Use bower to search for said library</li>
    <li>Add the discovered library to your <code>bower.json</code> file</li>
    <li>Run <code>bower install</code> or <code>bower update</code></li>
</ol>

<p>
    I've found that most projects registered with bower have minimized builds
    available (as well as the full source build), which is a huge boon in
    terms of performance. It also eliminates the "minimize the assets" step from
    my original list.
</p>

<p>
    To use bower, you'll need two files. The first is <code>.bowerrc</code> 
    which goes in your project root; you'll run <code>bower</code> from this 
    same directory.  This file tells bower how to run, and where to install 
    things, and, despite being an RC file, is written in JSON. Mine usually 
    looks like this:
</p>

<div class="example"><pre><code language="javascript">
{
    "directory": "public/assets/vendor"
}
</code></pre></div>

<p>
    The above tells bower to install dependencies in the <code>public/assets/vendor</code>
    subdirectory.
</p>

<p>
    The second file you need is <code>bower.json</code>. This file tells bower
    what asset packages you want to install, and the preferred version. (The file
    can also be used to define a package, just like with Composer or npm.) As an
    example, the following is a definition I used for an Apigility example:
</p>

<div class="example"><pre><code language="javascript">
{
    "name": "ag-contacts-demo",
    "version": "0.0.1",
    "ignore": [
        "**/.*"
    ],
    "dependencies": {
        "angular": "~1.2",
        "angular-resource": "~1.2",
        "angular-route": "~1.2",
        "bootstrap": ">=3.0.0",
        "font-awesome": "~3.2.1"
    }
}
</code></pre></div>

<p>
    Bower requires that packages use <a href="http://semver.org/">Semantic
    Versioning</a>. You can specify exact versions, minor versions, or major
    versions, combine them with comparison operators (<code>&lt;</code>, 
    <code>&gt;</code>, <code>=</code>, etc.), or use the "next significant release"
    operator ("~") to indicate a given version up to the next more general
    release (e.g., "~1.2" is equivalent to "&gt;=1.2,&lt;2.0").
</p>

<p>
    Once you have these defined, you should also add an entry to your 
    <code>.gitignore</code> file to exclude the directory you list in your
    <code>.bowerrc</code>; these files can be installed at build time,
    and thus help you keep your project repository lean. Per the above
    example:
</p>

<div class="example"><pre><code language="text">
public/assets/vendor/
</code></pre></div>

<p>
    At this point, run <code>bower install</code>, and bower will resolve
    all dependencies and install them where you want.
</p>

<p>
    At any point, you can list what packages bower has installed, as well
    as the versions it has installed. The <code>bower help</code> command
    is your friend should those needs arise.
</p>

<h2>Closing Thoughts</h2>

<p>
    I'm quite happy with the various tools emerging to make modern
    web development easier by allowing developers to more easily
    share their work, as well as ensure that all dependencies are
    easily installable. Bower is another tool in my arsenal as a web
    developer, giving me a consistent set of dependency management tools from my 
    server-side development all the way to my client-side application.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 3</title>
      <pubDate>Mon, 25 Feb 2013 12:29:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-25-restful-apis-with-zf2-part-3.html</link>
      <guid>http://mwop.net/blog/2013-02-25-restful-apis-with-zf2-part-3.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    In my <a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">previous</a> 
    <a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">posts</a>, I 
    covered basics of JSON hypermedia APIs using Hypermedia Application Language
    (HAL), and methods for reporting errors, including API-Problem and vnd.error.
</p>

<p>
    In this post, I'll be covering <em>documenting</em> your API -- techniques 
    you can use to indicate what HTTP operations are allowed, as well as convey 
    the full documentation on what endpoints are available, what they accept, 
    and what you can expect them to return.
</p>

<p>
    While I will continue covering general aspects of RESTful APIs in this 
    post, I will also finally introduce several ZF2-specific techniques.
</p><h2>Why Document?</h2>

<p>
    If you're asking this question, you've either never consumed software, or
    your software is perfect and self-documenting. I frankly don't believe 
    either one.
</p>

<p>
    In the case of APIs, those consuming the API need to know how to use it. 
</p>

<ul>
    <li>What endpoints are available? Which operations are available for each endpoint?</li>
    <li>What does each endpoint expect as a payload during the request?</li>
    <li>What can you expect as a payload in return?</li>
    <li>How will errors be communicated?</li>
</ul>

<p>
    While the promise of hypermedia APIs is that each response tells you the
    next steps available, you still, somewhere along the way, need more
    information - what payloads look like, which HTTP verbs should be used,
    and more. If you're <strong>not</strong> documenting your API, you're
    "doing it wrong."
</p>

<h2>Where Should Documentation Live?</h2>

<p>
    This is the much bigger question.
</p>

<p>
    Of the questions I raised above, detailing what should be documented, there
    are two specific types. When discussing what operations are available, 
    we have a technical solution in the form of the <code>OPTIONS</code>
    method and its counterpart, the <code>Allow</code> header. Everything
    else falls under end-user documentation.
</p>

<h2>OPTIONS</h2>

<p>
    The HTTP specification details the <code>OPTIONS</code> method as 
    idempotent, non-cacheable, and for use in detailing what operations
    are available for the given resource specified by the request URI. It
    makes specific mention of the <code>Allow</code> header, but does not
    limit what is returned for requests made via this method.
</p>

<p>
    The <code>Allow</code> header details the allowed HTTP methods for the
    given resource.
</p>

<p>
    Used in combination, you make an <code>OPTIONS</code> request to a URI,
    and it should return a response containing an <code>Allow</code> header;
    from that header value, you then know what other HTTP methods can be made
    to that URI.
</p>

<p>
    What this tells us is that our RESTful endpoint should do the following:
</p>

<ul>
    <li>
        When an <code>OPTIONS</code> request is made, return a response with
        an <code>Allow</code> header that has a list of the available HTTP
        methods allowed.
    </li>

    <li>
        For any HTTP method we do <em>not</em> allow, we should return a
        "405 Not Allowed" response.
    </li>
</ul>

<p>
    These are fairly easy to accomplish in ZF2. <em>(See? I promised I'd
    get to some ZF2 code in this post!)</em>
</p>

<p>
    When creating RESTful endpoints in ZF2, I recommend using
    <code>Zend\Mvc\Controller\AbstractRestfulController</code>. This controller
    contains an <code>options()</code> method which you can use to respond to
    an <code>OPTIONS</code> request. As with any ZF2 controller, returning
    a response object will prevent rendering and bubble out immediately so
    that the response is returned.
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    public function options()
    {
        $response = $this->getResponse();
        $headers  = $response->getHeaders();

        // If you want to vary based on whether this is a collection or an
        // individual item in that collection, check if an identifier from
        // the route is present
        if ($this->params()->fromRoute('id', false)) {
            // Allow viewing, partial updating, replacement, and deletion
            // on individual items
            $headers->addHeaderLine('Allow', implode(',', array(
                'GET',
                'PATCH',
                'PUT',
                'DELETE',
            )));
            return $response;
        }

        // Allow only retrieval and creation on collections
        $headers->addHeaderLine('Allow', implode(',', array(
            'GET',
            'POST',
        )));
        return $response;
    }
}
</code></pre></div>

<p>
    The next trick is returning the 405 response if an invalid option is used.
    For this, you can create a listener in your controller, and wire it to 
    listen at higher-than-default priority. As an example:
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\EventManager\EventManagerInterface;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    protected $allowedCollectionMethods = array(
        'GET',
        'POST',
    );

    protected $allowedResourceMethods = array(
        'GET',
        'PATCH',
        'PUT',
        'DELETE',
    );

    public function setEventManager(EventManagerInterface $events)
    {
        parent::setEventManager($events);
        $events->attach('dispatch', array($this, 'checkOptions'), 10);
    }

    public function checkOptions($e)
    {
        $matches  = $e->getRouteMatch();
        $response = $e->getResponse();
        $request  = $e->getRequest();
        $method   = $request->getMethod();

        // test if we matched an individual resource, and then test
        // if we allow the particular request method
        if ($matches->getParam('id', false)) {
            if (!in_array($method, $this->allowedResourceMethods)) {
                $response->setStatusCode(405);
                return $response;
            }
            return;
        }

        // We matched a collection; test if we allow the particular request 
        // method
        if (!in_array($method, $this->allowedCollectionMethods)) {
            $response->setStatusCode(405);
            return $response;
        }
    }
}
</code></pre></div>

<p>
    Note that I moved the allowed methods into properties; if I did the above,
    I'd refactor the <code>options()</code> method to use those properties as
    well to ensure they are kept in sync.
</p>

<p>
    Also note that in the case of an invalid method, I return a response object.
    This ensures that nothing else needs to execute in the controller; I
    discover the problem and return early.
</p>

<h2>End-User Documentation</h2>

<p>
    Now that we have the technical solution out of the way, we're still left 
    with the bulk of the work left to accomplish: providing end-user 
    documentation detailing the various payloads, errors, etc.
</p>

<p>
    I've seen two compelling approaches to this problem. The first builds on
    the <code>OPTIONS</code> method, and the other uses a hypermedia link in
    every response to point to documentation.
</p>

<p>
    The <code>OPTIONS</code> solution is this: <a 
    href="http://zacstewart.com/2012/04/14/http-options-method.html">use the 
    body of an <code>OPTIONS</code> response to provide documentation</a>.
    (Keith Casey <a href="http://vimeo.com/49613738">gave an excellent short 
    presentation about this at REST Fest 2012</a>).
</p>

<p>
    The <code>OPTIONS</code> method allows for you to return a body in the
    response, and also allows for content negotiation. The theory, then, is
    that you return media-type-specific documentation that details the
    methods allowed, and what they specifically accept in the body. While
    there is no standard for this at this time, the first article I linked
    suggested including a description, the parameters expected, and one or more 
    example request bodies for each HTTP method allowed; you'd likely also
    want to detail the responses that can be expected.
</p>

<div class="example"><pre><code language="javascript">
{
    "POST": {
        "description": "Create a new status",
        "parameters": {
            "type": {
                "type": "string",
                "description": "Status type -- text, image, or url; defaults to text",
                "required": false
            },
            "text": {
                "type": "string",
                "description": "Status text; required for text types, optional for others",
                "required": false
            },
            "image_url": {
                "type": "string",
                "description": "URL of image for image types; required for image types",
                "required": false
            },
            "link_url": {
                "type": "string",
                "description": "URL of image for link types; required for link types",
                "required": false
            }
        },
        "responses": [
            {
                "describedBy": "http://example.com/problems/invalid-status",
                "title": "Submitted status was invalid",
                "detail": "Missing text field required for text type"
            },
            {
                "id": "abcdef123456",
                "type": "text",
                "text": "This is a status update",
                "timestamp": "2013-02-22T10:06:05+0:00"
            }
        ],
        "examples": [
            {
                "text": "This is a status update"
            },
            {
                "type": "image",
                "text": "This is the image caption",
                "image_url": "http://example.com/favicon.ico"
            },
            {
                "type": "link",
                "text": "This is a description of the link",
                "link_url": "http://example.com/"
            },
        ]
    }
}
</code></pre></div>

<p>
    If you were to use this methodology, you would alter the 
    <code>options()</code> method such that it does not return a response
    object, but instead return a view model with the documentation.
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    protected $viewModelMap = array(/* ... */);

    public function options()
    {
        $response = $this->getResponse();
        $headers  = $response->getHeaders();

        // Get a view model based on Accept types
        $model    = $this->acceptableViewModelSelector($this->viewModelMap);

        // If you want to vary based on whether this is a collection or an
        // individual item in that collection, check if an identifier from
        // the route is present
        if ($this->params()->fromRoute('id', false)) {
            // Still set the Allow header
            $headers->addHeaderLine('Allow', implode(
                ',', 
                $this->allowedResourceMethods
            ));

            // Set documentation specification as variables
            $model->setVariables($this->getResourceDocumentationSpec());
            return $model;
        }

        // Allow only retrieval and creation on collections
        $headers->addHeaderLine('Allow', implode(
            ',',
            $this->allowedCollectionMethods
        ));
        $model->setVariables($this->getCollectionDocumentationSpec());
        return $model;
    }
}
</code></pre></div>

<p>
    I purposely didn't provide the implementations of the 
    <code>getResourceDocumentationSpec()</code> and 
    <code>getCollectionDocumentationSpec()</code> methods, as that will likely
    be highly specific to your application. Another possibility is to use
    your view engine for this, and specify a template file that has the
    fully-populated information. This would require a custom renderer when
    using JSON or XML, but is a pretty easy solution.
</p>

<p>
    <strong>However, there's one cautionary tale to tell</strong>, something I 
    already mentioned: <code>OPTIONS</code>, per the specification, is 
    <em>non-cacheable</em>.  What this means is that everytime somebody makes an 
    <code>OPTIONS</code> request, any cache control headers you provide will be 
    ignored, which means hitting the server for each and every request to the 
    documentation.  Considering documentation is static, this is problematic; 
    it has even prompted <a href="http://www.mnot.net/blog/2012/10/29/NO_OPTIONS">blog 
    posts urging you not to use OPTIONS for documentation</a>.
</p>

<p>
    Which brings us to the second solution for end-user documentation: a static
    page referenced via a hypermedia link.
</p>

<p>
    This solution is insanely easy: you simply provide a <code>Link</code>
    header in your response, and provide a <code>describedby</code> reference
    pointing to the documentation page:
</p>

<div class="example"><pre><code language="http">
Link: &lt;http://example.com/api/documentation.md&gt;; rel="describedby"
</code></pre></div>

<p>
    With ZF2, this is trivially easy to accomplish: create a route and endpoint
    for your documentation, and then a listener on your controller that adds
    the <code>Link</code> header to your response.
</p>

<p>
    The latter, adding the link header, might look like this:
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\EventManager\EventManagerInterface;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    public function setEventManager(EventManagerInterface $events)
    {
        parent::setEventManager($events);
        $events->attach('dispatch', array($this, 'injectLinkHeader'), 20);
    }

    public function injectLinkHeader($e)
    {
        $response = $e->getResponse();
        $headers  = $response->getHeaders();
        $headers->addHeaderLine('Link', sprintf(
            '<%s>; rel="describedby"', 
            $this->url('documentation-route-name')
        ));
    }
}
</code></pre></div>

<p>
    If you want to ensure you get a fully qualified URL that includes the 
    schema, hostname, and port, there are a number of ways to do that as
    well; the above gives you the basic idea.
</p>

<p>
    Now, for the route and endpoint, there are tools that will help you
    simplify that task as well, in the form of a couple of ZF2 modules:
    <a href="https://github.com/weierophinney/PhlySimplePage">PhlySimplePage</a>
    and <a href="https://github.com/Soflomo/Prototype">Soflomo\Prototype</a>.
    <em>(Disclosure: I'm the author of PhlySimplePage.)</em>
</p>

<p>
    Both essentially allow you to specify a route and the corresponding
    template name to use, which means all you need to do is provide a little
    configuration, and a view template. <code>Soflomo\Prototype</code> has
    slightly simpler configuration, so I'll demonstrate it here:
</p>

<div class="example"><pre><code language="php">
return array(
    'soflomo_prototype' => array(
        'documentation-route-name' => array(
            'route'    => '/api/documentation',
            'template' => 'api/documentation',
        ),
    ),
    'view_manager' => array(
        'template_map' => array(
            'api/documentation' => __DIR__ . '/../view/api/documentation.phtml',
        ),
    ),
);
</code></pre></div>

<p>
    I personally have been using the <code>Link</code> header solution, as it's
    so simple to implement. It does <em>not</em> write the documentation for you,
    but thinking about it early and implementing it helps ensure you at least
    start writing the documentation, and, if you open source your project,
    you may find you have users who will write the documentation for you if
    they know where it lives.
</p>

<h2>Conclusions</h2>

<p>
    Document your API, or either nobody will use it, or all you're hear are
    complaints from your users about having to guess constantly about how to
    use it. Include the following information:
</p>

<ul>
    <li>What endpoint(s) is (are) available.</li>
    <li>Which operations are available for each endpoint.
        <ul>
            <li>What payloads are expected by the endpoint.</li>
            <li>What payloads can a user expect in return.</li>
            <li>What media types may be used for requests.</li>
            <li>What media types may be expected in responses.</li>
        </ul>
    </li>
</ul>

<p>
    Additionally, make sure that you do the <code>OPTIONS</code>/<code>Allow</code>
    dance; don't just accept any request method, and report the standard
    405 response for methods that you will not allow. Make sure you differentiate
    these for collections versus individual resources, as you likely may
    allow replacing or updating an individual resource, but likely will not
    want to do the same for a whole collection!
</p>

<h2>Next time</h2>

<p>
    So far, I've covered the basics of RESTful JSON APIS, specifically 
    recommending Hypermedia Application Language (HAL) for providing hypermedia
    linking and relations. I've covered error reporting, and provided two
    potential formats (API-Problem and vnd.error) for use with your APIs.
    Now, in this article, I've shown a bit about documenting your API both
    for machine consumption as well as end-users. What's left?
</p>

<p>
    In upcoming parts, I'll talk about ZF2's <code>AbstractRestfulController</code>
    in more detail, as well as how to perform some basic content negotiation.
    I've also had requests about how one might deal with API versioning, and will
    attempt to demonstrate some techniques for doing that as well. Finally,
    expect to see a post showing how I've tied all of this together in a 
    general-purpose ZF2 module so that you can ignore all of these posts and simply
    start writing APIs.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">Part 1</a></li>
    <li><a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">Part 2</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 2</title>
      <pubDate>Wed, 13 Feb 2013 13:40:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-13-restful-apis-with-zf2-part-2.html</link>
      <guid>http://mwop.net/blog/2013-02-13-restful-apis-with-zf2-part-2.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    In my <a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">last post</a>,
    I covered some background on REST and the Richardson Maturity Model, and some
    emerging standards around hypermedia APIs in JSON; in particular, I outlined
    aspects of Hypermedia Application Language (HAL), and how it can be used to
    define a generic structure for JSON resources.
</p>

<p>
    In this post, I cover an aspect of RESTful APIs that's often overlooked:
    reporting problems.
</p><h2>Background</h2>

<p>
    APIs are useful when they're working. But when they fail, they're only 
    useful if they provide us with meaningful information; if all I get is
    a status code, and no indication of what caused the issue, or where I might
    look for more information, I get frustrated.
</p>

<p>
    In consuming APIs, I've come to the following conclusions:
</p>

<ul>
    <li>
        Error conditions need to provide detailed information as to what went 
        wrong, and what steps I may be able to take next. An error code with
        no context gives me nothing to go on.
    </li>

    <li>
        Errors need to be reported consistently. Don't report the error one way
        one time, and another way the next.
    </li>

    <li>
        <strong>DO</strong> use HTTP status codes to indicate an error happened.
        Nothing is more irksome than getting back a 200 status with an error 
        payload.
    </li>

    <li>
        Errors should be reported in a format I have indicated I will Accept 
        (as in the HTTP header). Perhaps the only think more irksome than a 200
        status code for an error is getting back an HTML page when I expect 
        JSON.
    </li>
</ul>

<h2>Why Status Codes Aren't Enough</h2>

<p>
    Since REST leverages and builds on HTTP, an expedient solution for reporting
    problems is to simply use <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP status codes</a>. 
    These are well understood by web developers, right?
</p>

<p>
    <code>4xx</code> error codes are errors made by the requestor, and are actually fairly 
    reasonable to use for reporting things such as lack of authorization tokens,
    incomplete requests, unsupportable operations, or non-supported media types.
</p>

<p>
    But what happens when the error is on the server - because something has
    gone wrong such as inability to reach your persistence layer or credential
    storage? The <code>5xx</code> series of status codes is sparse and wholly unsuited to
    reporting errors of these types -- <em>though you'll likely still want to use
    a <code>500</code> status to report the failure</em>. But what do you present to the consumer
    so that they know whether or not to try again, or what to report to you
    so that you can fix the issue?
</p>

<p>
    A status code simply isn't enough information most of the time. Yes, you 
    want to define standard status codes so that your clients can perform
    reasonable branching, but you also need a way to communicate <em>details</em>
    to the end-user, so that they can log the information for themselves, display
    information to their own end-users, and/or report it back to you so you can
    do something to resolve the situation.
</p>

<h2>Custom Media Types</h2>

<p>
    The first step is to use a custom media type. Media types are typically 
    both a name as well as a structure -- and the latter is what we're after
    when it comes to error reporting. 
</p>

<p>
    If we return a response using this media type, the client then knows how
    to parse it, and can then process it, log it, whatever.
</p>

<p>
    Sure, you can make up your own format -- as long as you are consistent
    in using it, and you document it. But personally, I don't like inventing
    new formats when standard formats exist already. Custom formats mean that 
    custom clients are required for working with the services; using a standard
    format can save effort and time.
</p>

<p>
    In the world of JSON, I've come across two error media types that appear to
    be gaining traction: <code>application/api-problem+json</code> and 
    <code>application/vnd.error+json</code>
</p>

<h3>API-Problem</h3>

<p>
    This particular media type is <a 
    href="http://tools.ietf.org/html/draft-nottingham-http-problem-02">via the 
    IETF</a>. Like HAL, it provides formats in both JSON and XML, making it 
    a nice cross-platform choice.
</p>

<p>
    As noted already, the media type is <code>application/api-problem+json</code>.
    The representation is a single resource, with the following properties:
</p>

<ul>
    <li>
        <strong>describedBy</strong>: a URL to a document describing the error condition (required)
    </li>

    <li>
        <strong>title</strong>: a brief title for the error condition (required)
    </li>

    <li>
        <strong>httpStatus</strong>: the HTTP status code for the current request (optional)
    </li>

    <li>
        <strong>detail</strong>: error details specific to this request (optional)
    </li>

    <li>
        <strong>supportId</strong>: a URL to the specific problem occurrence (e.g., to a log message) (optional)
    </li>
</ul>

<p>
    As an example:
</p>

<div class="example"><pre><code language="http">
HTTP/1.1 500 Internal Error
Content-Type: application/api-problem+json

{
    "describedBy": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html",
    "detail": "Status failed validation",
    "httpStatus": 500,
    "title": "Internal Server Error"
}
</code></pre></div>

<p>
    The specification allows a large amount of flexibility -- you can have your 
    own custom error types, so long as you have a description of them to link 
    to. You can provide as little or as much detail as you want, and even 
    decide what information to expose based on environment.
</p>

<p>
    I personally like to point to the HTTP status code definitions, and then 
    provide request-specific detail; I find this gives quick and simple results 
    that I can later shape as I add more detail to my API. However, the 
    specification definitely encourages you to have unique error types with 
    discrete URIs that describe them -- never a bad thing when creating APIs.
</p>

<h3>vnd.error</h3>

<p>
    This is a <a href="https://github.com/blongden/vnd.error">proposed media 
    type</a> within the HAL community. Like HAL, it provides formats in both 
    JSON and XML, making it a nice cross-platform choice.
</p>

<p>
    It differentiates from API-Problem in a few ways. First, it allows, and 
    even encourages, reporting collections of errors. If you consider PHP 
    exceptions and the fact that they support "previous" exceptions, this is a 
    powerful concept; you can report the entire chain of errors that led to the 
    response.  Second, it encourages pushing detail out of the web service; 
    errors include a "logRef" property that points to where the error detail lives. 
    This is probably better illustrated than explained.
</p>

<p>
    The response payload is an array of objects. Each object has the following 
    members:
</p>

<ul>
    <li>
        <strong>logRef</strong>: a unique identifier for the specific error which can then be
        used to identify the error within server-side logs (required)
    </li>

    <li>
        <strong>message</strong>: the error message itself (required)
    </li>

    <li>
        <strong>_links</strong>: HAL-compatible links. Typically, "help", "describes", and/or 
        "describedBy" relations will be defined here.
    </li>
</ul>

<p>
    As an example, let's consider the API-Problem example I had earlier, and
    provide a vnd.error equivalent:
</p>

<div class="example"><pre><code language="http">
HTTP/1.1 500 Internal Error
Content-Type: application/vnd.error+json

[
    {
        "logRef": "someSha1HashMostLikely",
        "message": "Status failed validation",
        "_links": {
            "describedBy": {"href": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html"}
        }
    }
]
</code></pre></div>

<p>
    vnd.error basically begs you to create custom error types, with documentation 
    end-points that detail the source of the error and what you can do about it 
    (this is true of API-Problem as well).
</p>

<p>
    The requirement to include a log reference ("logRef") and have it be unique 
    can be a stumbling block to implementation, however, as it requires effort 
    for uniquely identifying requests, and logging. However, both the 
    identification and logging can be automated.
</p>

<h2>Summary</h2>

<p>
    Error reporting in APIs is as important as the normal resource payloads 
    themselves. Without good error reporting, when an API raises errors, 
    clients have difficulty understanding what they can do next, and cannot
    provide you, the API provider, with information that will allow you to
    debug on the server side.
</p>

<p>
    As noted at the beginning of the article, if you follow the rules below,
    you'll make consumers of your API happier and more productive.
</p>

<ul>
    <li>
        <strong>DO</strong> use appropriate HTTP status codes to indicate an 
        error happened.
    </li>

    <li>
        Report errors in a format I have indicated I will Accept 
        (as in the HTTP header). 
    </li>
    <li>
        Report errors consistently. Don't report the error one way one time, 
        and another way the next. Standardize on a specific error-reporting 
        media type .  While you <em>can</em> create your own error structure, I 
        recommend using documented, accepted standards. This will make clients 
        more re-usable, and make many of your decisions for you.
    </li>

    <li>
        Provide detailed information as to what went wrong, and what steps I 
        may be able to take next. Provide documentation for each type of error, 
        and link to that documentation from your error payloads.
    </li>

</ul>

<p>
    Which brings me to...
</p>

<h2>Next time</h2>

<p>
    I realize I still haven't covered anything specific to ZF2, but I'll start 
    next time, when I cover the next topic: documenting your API. An 
    undocumented API is a useless API, so it's good to start baking 
    documentation in immediately. I'll survey some of the possibilities and how 
    they can be implemented in ZF2 in the next installment, and then we can get 
    our hands dirty with actual API development.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">Part 1</a></li>
    <li><a href="/blog/2013-02-25-restful-apis-with-zf2-part-3.html">Part 3</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 1</title>
      <pubDate>Wed, 13 Feb 2013 13:40:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-11-restful-apis-with-zf2-part-1.html</link>
      <guid>http://mwop.net/blog/2013-02-11-restful-apis-with-zf2-part-1.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    RESTful APIs have been an interest of mine for a couple of years, but due
    to <a href="http://framework.zend.com/blog//zend-framework-2-0-0-stable-released.html">circumstances</a>,
    I've not had much chance to work with them in any meaningful fashion until
    recently.
</p>

<p>
    <a href="http://akrabat.com/">Rob Allen</a> and I proposed a workshop for
    <a href="http://conference.phpbenelux.eu/2013/">PHP Benelux 2013</a> 
    covering RESTful APIs with ZF2. When it was accepted, it gave me the perfect
    opportunity to dive in and start putting the various pieces together.
</p><h2>Background</h2>

<p>
    I've attended any number of conference sessions on API design, read 
    countless articles, and engaged in quite a number of conversations. Three
    facts keep cropping up:
</p>

<ol>
    <li>JSON is fast becoming the preferred exchange format due to the ease 
    with which it de/serializes in almost every language.</li>
    <li>The "holy grail" is <a 
    href="http://martinfowler.com/articles/richardsonMaturityModel.html">Richardson 
    Maturity Model</a> Level 3.</li>
    <li>It's really hard to achieve RMM level 3 with JSON.</li>
</ol>

<h3>Richardson Maturity Model</h3>

<p>
    As a quick review, the Richardson Maturity Model has the following 4 levels:
</p>

<ul>
    <li>Level 0: "The swamp of POX." Basically, a service that uses TCP for 
        transport, primarily as a form of remote procedure call (RPC). 
        Typically, these are not really leveraging HTTP in any meaningful 
        fashion; most systems will use HTTP POST for all interactions. Also, 
        you will often have a single endpoint for all interactions, regardless 
        of whether or not they are strictly related. XML-RPC, SOAP, and 
        JSON-RPC fall under this category.
    </li>

    <li>Level 1: "Resources." In these services, you start breaking the service
        into multiple services, one per "resource," or, in object oriented terms,
        per object. This means a distinct URL per object, which means each
        has its own distinct identity on the web; this often extends not only 
        to the collection of objects, but to individual objects under the 
        collection as well (e.g., "/books" as well as "/books/life-of-pi"). The 
        service may still be RPC in nature, however, and, at this level, often 
        is still using a single HTTP method for all interactions with the 
        resource.
    </li>

    <li>Level 2: "HTTP Verbs." At this level, we start using HTTP verbs with
        our services in the way the HTTP specification intends. GET is for safe 
        operations, and should be cacheable; POST is used for creation and/or 
        updating; DELETE can be used to delete a resource; etc. Rather than 
        doing RPC style methods, we leverage HTTP, occasionally passing 
        additional parameters via the query string or request body.  
        Considerations such as HTTP caching and idempotence are taken into 
        account.
    </li>

    <li>Level 3: "Hypermedia Controls." Building on the previous level, our
        resource representations now also include <em>links</em>, which indicate
        what we can <em>do next</em>. At this level, our API becomes practically
        self-describing; given a single end-point, we should be able to start
        crawling it, using the links in a representation to lead us to the next
        actions.
    </li>
</ul>

<p>
    When I first started playing with web services around a decade ago, 
    everything was stuck at Level 0 or Level 1 -- usually with Level 1 users 
    downgrading to Level 0 because Level 0 offerred consistency and 
    predictability if you chose to use a service type that had a defined 
    envelope format (such as XML-RPC or SOAP).  (I even wrote the XML-RPC 
    server implementation for Zend Framework because I got sick of writing 
    one-off parsers/serializers for custom XML web service implementations.
    When you're implementing many services, predictability is a huge win.)
</p>

<p>
    A few years ago, I started seeing a trend towards Level 2. Web developers
    like the simplicity of using HTTP verbs, as they map very well to <a 
    href="http://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a>
    operations -- the bread and butter of web development. Couple this concept
    with JSON, and it becomes trivially simple to both create a web service, as
    well as consume it.
</p>

<p>
    <em>I'd argue that the majority of web developers are quite happy to be at 
    Level 2 -- and have no problem staying there. They're productive, and the 
    concepts are easy -- both to understand and to implement.</em>
</p>

<p>
    Level 3, though, is where it becomes really interesting. The idea that
    I can examine the represention <em>alone</em> in order to understand what
    I can do next is very intriguing and empowering.
</p>

<h3>JSON and Hypermedia</h3>

<p>
    With XML, hypermedia basically comes for free. Add some &lt;link&gt; 
    elements to your representation, and you're done -- and don't forget the 
    link <code>rel</code>ations!
</p>

<p>
    JSON, however, is another story.
</p>

<p>
    Where do the links go? <em>There is no single, defined way to represent a 
    hyperlink in JSON.</em>
</p>

<p>
    Fortunately, there are some emerging standards. 
</p>

<p>
    First is use of the <a href="http://www.w3.org/wiki/LinkHeader">"Link" HTTP 
    header</a>. While the page I linked shows only a single link in the
    header, you can have multiple links separated by commas. GitHub uses this
    when providing pagination links in their API. Critics will point out that
    the HTTP headers are not technically part of the representation, however;
    strict interpetations of REST and RMM indicate that the hypermedia links
    should be part of the resource representation. Regardless, having the links
    in the HTTP headers is useful for pre-traversal of a service, as you can
    perform HEAD requests only to discover possible actions and workflows.
</p>

<p>
    <a 
    href="http://amundsen.com/media-types/collection/format/">Collection+JSON</a>
    is interesting, as it describes the entire JSON envelope. My one criticism
    is that it details too much; whenever I see a format that dictates how to 
    describe types, I think of XML-RPC or SOAP, and get a little twitchy. It's
    definitely worth a look, though.
</p>

<p>
    What's captured my attention of late, however, is 
    <a href="http://stateless.co/hal_specification.html">Hypertext Application Language</a>,
    or HAL for short. HAL has very few rules, but succinctly describes both how
    to provide hypermedia in JSON as well as how to represent embedded resources
    - the two things that most need standardized structure in JSON. It does this
    while still providing a generic media type, and also describing a mirror 
    image XML format!
</p>

<h3>HAL Media Types</h3>

<p>
    HAL defines two generic media types: <code>application/hal+xml</code> and
    <code>application/hal+json</code>. You will use these as the response
    Content-Type, as they describe the response representation; the client
    can simply request <code>application/json</code>, and the response
    format remains compatible.
</p>

<h3>HAL and Links</h3>

<p>
    HAL provides a very simple structure for JSON hypermedia links. First, all 
    resource representations must contain hypermedia links, and all links are 
    provided in a "_links" object:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
    }
}
</code></pre></div>

<p>
    Second, links are properties of this object. The property name is the link
    relation, and the value is an object containing minimally an "href" 
    property.
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1234"}
    }
}
</code></pre></div>

<p>
    If a given relation can have multiple links, you provide instead an array
    of objects:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1234"},
        "conversation": [
            {"href": "http://example.com/api/status/1237"},
            {"href": "http://example.com/api/status/1241"}
        ]
    }
}
</code></pre></div>

<p>
    Individual links can contain other attributes as desired -- I've seen
    people include the relation again so that it's self-contained in the link 
    object, and it's not uncommon to include a title or name.
</p>

<h3>HAL and Resources</h3>

<p>
    HAL imposes no structure over resources other than requiring the hypermedia 
    links; even then, you typically do not include the hypermedia links when 
    making a request of the web service; the hypermedia links are included only 
    in the representations <em>returned</em> by the service.
</p>

<p>
    So, as an example, you would POST the following:
</p>

<div class="example"><pre><code language="http">
POST /api/status
Host: example.com
Accept: application/json
Content-Type: application/json

{
    "status": "This is my awesome status update!",
    "user": "mwop"
}
</code></pre></div>

<p>
    And from that request, you'd receive the following:
</p>

<div class="example"><pre><code language="http">
201 Created
Location: http://example.com/api/status/1347
Content-Type: application/hal+json

{
    "_links": {
        "self": {"href": "http://example.com/api/status/1347"}
    },
    "id": "1347",
    "timestamp": "2013-02-11 23:33:47",
    "status": "This is my awesome status update!",
    "user": "mwop"
}
</code></pre></div>

<h3>HAL and Embedded Resources</h3>

<p>
    The other important thing that HAL defines is how to <em>embed</em>
    resources. Why is this important? If the resource references other
    resources, you will want to be able to link to them so you can perform
    operations on them, too.
</p>

<p>
    Embedded resources are represented inside an "_embedded" object of the
    representation, and, as resources, contain their own "_links" object as 
    well. Each resource you embed is assigned to a property of that
    object, and if multiple objects of the same type are returned, an array
    of resources is assigned. In fact, this latter is how you represent
    <em>collections</em> in HAL.
</p>

<p>
    Let's consider a simple example first. In previous code samples, I have
    a "user" that's a string; let's make that an embedded resource instead.
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1347"}
    },
    "id": "1347",
    "timestamp": "2013-02-11 23:33:47",
    "status": "This is my awesome status update!",
    "_embedded": {
        "user": {
            "_links": {
                "self": {"href": "http://example.com/api/user/mwop"}
            }
            "id": "mwop",
            "name": "Matthew Weier O'Phinney",
            "url": "http://mwop.net"
        }
    }
}
</code></pre></div>

<p>
    I've moved the "user" out of the representation, and into the "_embedded"
    object -- because this is where you define embedded resources. Note that
    the "user" is a standard HAL resource itself -- containing hypermedia links.
</p>

<p>
    Now let's look at a collection:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status"},
        "next": {"href": "http://example.com/api/status?page=2"},
        "last": {"href": "http://example.com/api/status?page=100"}
    },
    "count": 2973,
    "per_page": 30,
    "page": 1,
    "_embedded": {
        "status": [
            {
                "_links": {
                    "self": {"href": "http://example.com/api/status/1347"}
                },
                "id": "1347",
                "timestamp": "2013-02-11 23:33:47",
                "status": "This is my awesome status update!",
                "_embedded": {
                    "user": {
                        "_links": {
                            "self": {"href": "http://example.com/api/user/mwop"}
                        }
                        "id": "mwop",
                        "name": "Matthew Weier O'Phinney",
                        "url": "http://mwop.net"
                    }
                }
            }
            /* ... */
        ]
    }
}
</code></pre></div>

<p>
    Note that the "status" property is an array; semantically, all resources
    under this key are of the same type. Also note that the parent resource
    has some additional link relations -- these are related to pagination, and
    allow a client to determine what the next and last pages are (and, if we 
    were midway into the collection, previous and first pages). Since the 
    collection is also a resource, it has some interesting metadata -- how
    many resources are in the collection, how many we represent per page, and
    what the current page is.
</p>

<p>
    Also note that you can nest resources -- simply include an "_embedded" 
    object inside an embedded resource, with additional resources, as I've
    done with the "user" resource inside the status resource shown here. It's 
    turtles all the way down.
</p>

<h2>Next Time</h2>

<p>
    The title of this post indicates I'll be talking about building RESTful 
    APIs with ZF2 -- but so far, I've not said anything about ZF2.
</p>

<p>
    I'll get there. But there's another detour to take: reporting errors.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">Part 2</a></li>
    <li><a href="/blog/2013-02-25-restful-apis-with-zf2-part-3.html">Part 3</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>OpenShift, Cron, and Naked Domains</title>
      <pubDate>Sun, 30 Dec 2012 15:52:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-30-openshift-cron-and-naked-domains.html</link>
      <guid>http://mwop.net/blog/2012-12-30-openshift-cron-and-naked-domains.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    As an experiment, I migrated my website over to <a 
    href="http://openshift.redhat.com">OpenShift</a> yesterday. I've been hosting
    a pastebin there already, and have found the service to be both straightforward
    and flexible; it was time to put it to a more thorough test.
</p>

<p>
    In the process, I ran into a number of interesting issues, some of which took quite
    some time to resolve; this post is both to help inform other potential users of the
    service, as well as act as a reminder to myself.
</p><h2>Cron</h2>

<p>
    OpenShift offers a <a href="http://en.wikipedia.org/wiki/Cron">Cron</a> cartridge,
    which I was excited to try out.<sup><a href="#f1">1</a></sup>
</p>

<p>
    The basics are quite easy. In your repository's <code>.openshift</code> 
    directory is a <code>cron</code> subdirectory, further divided into 
    <code>minutely</code>, <code>hourly</code>, <code>daily</code>, <code>weekly</code>,
    and <code>monthly</code> subdirectories. You drop a script you want to run
    into one of these directories, and push your changes upstream.
</p>

<p>
    The problem is: what if I want a job to run at a specific time daily? or on 
    the quarter hour? or on a specific day of the week?
</p>

<p>
    As it turns out, you can manage all of the above, just not quite as succinctly as
    you would in a normal crontab. Here, for example, is a script that I run at 
    5AM daily; I placed it in the <code>hourly</code> directory so that it can test
    more frequently:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
if [ `date +%H` == "05" ]
then
    (
        export PHP=/usr/local/zend/bin/php ;
        cd $OPENSHIFT_REPO_DIR ; 
        $PHP public/index.php phlycomic fetch all ; 
        $PHP public/index.php phlysimplepage cache clear --page=pages/comics 
    )
fi
</code></pre></div>

<p>
    And here's one that runs on the quarter-hour, placed in the <code>minutely</code>
    directory:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
MINUTES=`date +%M`

for i in "00" "15" "30" "45";do
    if [ "$MINUTES" == "$i" ];then
        (
            export PHP=/usr/local/zend/bin/php ;
            cd $OPENSHIFT_REPO_DIR ;
            $PHP public/index.php githubfeed fetch 
        )
    fi
done
</code></pre></div>

<p>
    The point is that if you need more specificity, push the script into the 
    next more specific directory, and test against the time of execution.
</p>

<h2>Naked Domains</h2>

<p>
    Naked domains are domains without a preceding subdomain. In my case, this
    means "mwop.net", vs. "www.mwop.net".
</p>

<p>
    The problem that cloud hosting presents is that the IP address on which you
    are hosted can change at any time, for a variety of reasons. As such, you
    typically cannot use DNS A records to point to your domain; the recommendation
    is to use a CNAME record that points the domain to a "virtual" domain 
    registered with your cloud hosting provider.
</p>

<p>
    However, most domain registrars and DNS providers do not let you do this for
    a naked domain, particularly if you also have MX or other records associated
    with that naked domain.
</p>

<p>
    Some registrars will allow you to forward the A record to a subdomain. I tried
    this, but had limited success; I personally found that I ended up in an infinite
    loop situation when doing the DNS lookup.
</p>

<p>
    Another solution is to have a redirect in place for your naked domain to the
    subdomain, which can then be a CNAME record. Typically, this would require you
    have a web server under your control with a fixed IP that then simply redirects
    to the subdomain. Fortunately, there's an easier solution: <a 
    href="http://wwwizer.com/naked-domain-redirect">wwwizer</a>. You simply point
    your naked domain A record to the wwwizer IP address, and they will do a 
    redirect to your <code>www</code> subdomain.
</p>

<p>
    I implemented wwwizer on my domain (which is why you'll see "www.mwop.net" in
    your location bar), and it's been working flawlessly since doing so.
</p>

<h4>Private repositories</h4>

<p>
    I keep my critical site settings in a private repository, which allows me 
    to version them while keeping the credentials they hold out of the public eye.
    This means, however, that I need to use <a href="https://help.github.com/articles/managing-deploy-keys">GitHub deploy keys</a> on my server
    in order to retrieve changes.
</p>

<p>
    This was simple enough: I created an <code>ssh</code> subdirectory in my
    <code>$OPENSHIFT_DATA_DIR</code> directory, and generated a new SSH keypair.
</p>

<p>
    The problem was telling SSH to <em>use</em> this key when fetching changes.
</p>

<p>
    The solution is to use a combination of <code>ssh-agent</code> and <code>ssh-add</code>,
    and it looks something like this:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
ssh-agent `ssh-add $OPENSHIFT_DATA_DIR/ssh/github-key && (
    cd $OPENSHIFT_DATA_DIR/config ; 
    git fetch origin ; 
    git rebase origin/mwop.net.config
)`
</code></pre></div>

<p>
    After testing the above, I put this in a <code>pre_build</code> script in 
    my OpenShift configuration so that I can autoupdate my private 
    configuration on each build. However, I discovered a new problem: when
    a build is being done, the <code>ssh-agent</code> is not available, which
    means the above cannot be executed. I'm still trying to find a solution.
</p>

<h2>Fin</h2>

<p>
    I'm pretty happy with the move. I don't have to do anything special
    to automate deployment, and all my cronjobs and deployment scripts are now
    self-contained in the repository, which makes my site more portable.
    While a few things could use more documentation, all the pieces are there
    and discoverable with a small amount of work.
</p>

<p>
    I'll likely give some other PaaS providers a try in the future, but for 
    the moment, I'm quite happy with the functionality and flexibility of 
    OpenShift.
</p>

<h4>Footnotes</h4>

<ul>
    <li id="f1">Zend Server's JobQueue can also be used as a cron replacement, 
    but I was not keen on exposing the job functionality via HTTP.</li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>On php-fig and Shared Interfaces</title>
      <pubDate>Thu, 20 Dec 2012 20:23:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-20-on-shared-interfaces.html</link>
      <guid>http://mwop.net/blog/2012-12-20-on-shared-interfaces.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    This is a post I've been meaning to write for a long time, and one requested
    of me personally by <a href="http://www.rooftopsolutions.nl/blog/">Evert 
    Pot</a> during the Dutch PHP Conference in June 2012. It details some observations
    I have of php-fig, and hopefully will serve as a record of why I'm not
    directly participating any longer.
</p>

<p>
    I was a founding member of the <a href="http://www.php-fig.org/">Framework 
    Interoperability Group</a>, now called "php-fig". I was one of around a dozen 
    folks who sat around a table in 2009 in Chicago during php|tek and started 
    discussions about what we could all do to make it possible to work better 
    together between our projects, and make it simpler for users to pick and choose 
    from our projects in order to build the solutions to their own problems.
</p>

<p>
    The first "standard" that came from this was <a 
    href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md">PSR-0</a>, 
    which promoted a standard class naming convention that uses a 1:1 relationship 
    between the namespace and/or vendor prefix and the directory hierarchy, and the 
    class name and the filename in which it lives. To this day, there are both 
    those who hail this as a great step forward for cooperation, and simultaneously 
    others who feel it's a terrible practice. 
</p>

<p>
    And then nothing, for years. But a little over a year ago, there was a new 
    push by a number of folks wanting to do more. Paul Jones did a remarkable 
    job of spearheading the next <a href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md">two</a> 
    <a href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-2-coding-style-guide.md">standards</a>, 
    which centered around coding style. Again, just like with PSR-0, we had 
    both those feeling it was a huge step forward, and those who loathe the 
    direction.
</p>

<p>
    What was interesting, though, was that once we started seeing some new energy
    and momentum, it seemed that <em>everyone</em> wanted a say. And we started 
    getting dozens of folks a week asking to be voting members, and new proposal
    after new proposal. Whether or not somebody likes an existing standard, they
    want to have backing for a standard they propose.
</p>

<p>
    And this is when we started seeing proposals surface for shared interfaces, first
    around caching, and now around logging (though the latter is the first up for
    vote).
</p><h2>Shared Interfaces</h2>

<p>
    The idea around shared interfaces is simple: if we can come to a consensus on
    the basic interface for a common application task, libraries and frameworks
    can typehint on that shared interface, allowing developers to drop in the 
    implementation of their choosing -- or even a standard, reference implementation.
    The goal is to prevent Not Invented Here (NIH) syndrome, as well as to make
    it simpler to re-use components between one library and another. As an example,
    if you're using Framework A, and it has a caching library, and you're consuming
    ORM B, you'd be able to pass the same cache object to the ORM as you use in the
    framework.
</p>

<p>
    Great goals, really.
</p>

<p>
    But I'm not sure I buy into them.
</p>

<h2>Problems</h2>

<p>
    First, I agree that NIH is a problem.
</p>

<p>
    Second, I <em>also</em> think there's space for <em>multiple 
    implementations</em> of any given component. Often there are different 
    approaches that different authors will take: one might focus on 
    performance, another on having multiple adapters for providing different 
    capabilities, etc. Sometimes having a different background will present 
    different problem areas you want to resolve. As such, having multiple 
    implementations can be a very good thing; developers can look at what each 
    provides, and determine which solves the particular issues presented in the 
    current project.
</p>

<p>
    Because of this latter point, I have my reservations about shared interfaces.
</p>

<p>
    What if a particular approach requires deviating from the shared interface in 
    order to accomplish its goals? Additionally, in order to keep the greatest
    amount of compatibility between projects, shared interfaces tend to be so
    generic that specific implementations require developers to do a ton of manual
    type checking and munging of parameters, leading to more overhead, more difficulty
    testing and maintaining, and more difficulty documenting and understanding.
</p>

<p>
    As an example, consider the following (made up) signature for a log method:
</p>

<div class="example"><pre><code language="php">
public function log($message, array $context = null);
</code></pre></div>

<p>
    What if your library supports an idea of priorities? Where would that 
    information go in the above signature -- and would that differ between 
    libraries -- would one library use the key for a completely different 
    purpose? What about logging objects -- the signature doesn't say you can't, 
    but how would I know if a specific implementation supports it, and won't 
    blow up if I do pass one? Why must the <code>$context</code> be an array -- 
    why won't any <code>Traversable</code> or <code>ArrayAccess</code> object 
    work?
</p>

<p>
    Basically, by being overly generic, the signature becomes a liability for
    those implementing the interface; it prevents meaningful interoperability
    and leads to splintering implementations.
</p>

<p><em>
    (Please note: the above is completely fictional and has no bearing
    on current proposed or accepted standards. It is a thought exercise
    only.)
</em></p>

<p>
    Furthermore, if a given project writes their own implementation of a 
    component, and it has specialized features, why would they want to typehint
    on a generic, shared interface that doesn't implement those features? This
    would be counter-intuitive, as the project would then need to either check on
    additional interfaces for the specialized capabilities, duck-type, etc. --
    all of which make for more maintenance and code.
</p>

<p>
    In summary, my primary problem with the idea of shared interfaces is that I 
    feel there is always room for new thinking and ideas in any given problem 
    space, and that this thinking should not be restricted by what already 
    exists. Secondarily, I feel that it's okay for a given project to be 
    selective about what capabilities it requires for its internal consumption 
    and consistency, and should not limit itself to a standardized interface.
</p>

<h2>But, but, SHARING</h2>

<p>
    <em>Remember, the first point I made was that I think NIH is a 
    problem.</em> How do I reconcile that with a firm stance against shared 
    interfaces?
</p>

<p>
    Easy: <a href="http://en.wikipedia.org/wiki/Bridge_pattern">bridges</a> 
    and/or <a href="http://en.wikipedia.org/wiki/Adapter_pattern">adapters</a>.
</p>

<p>
    Let's go back to that example of Framework A, its caching library, and working
    with ORM B.
</p>

<p>
    Let's assume that ORM B defines an interface for caching, and let's say it
    looks like this:
</p>

<div class="example"><pre><code language="php">
interface CacheInterface
{
    public function set($key, $data);
    public function has($key);
    public function get($key);
}
</code></pre></div>

<p>
    Furthermore, we'll assume that the expected parameter values and return types
    are documented.
</p>

<p>
    What we as a consumer of both Framework A and ORM B can do is build an 
    <em>implementation</em> of <code>CacheInterface</code> that accepts a cache
    instance from Framework A, and proxies the various interface methods to that
    instance.
</p>

<div class="example"><pre><code language="php">
class FrameworkACache implements CacheInterface
{
    protected $cache;

    public function __construct(Cache $cache)
    {
        $this->cache = $cache;
    }

    public function set($key, $data)
    {
        $item = new CacheItem($key, $data);
        $this->cache->setItem($item);
    }

    public function has($key)
    {
        return $this->cache->exists($key);
    }

    public function get($key)
    {
        $item = $this->cache->getItem($key);
        return $item->getData();
    }
}
</code></pre></div>

<p>
    Assuming your code is well-decoupled, and you're using some sort of Inversion of
    Control container, you can likely create a factory for your ORM that will grab
    the above class, with the cache injected, and inject it into the ORM instance. 
    Yes, it's a bit more work, but it's difficult to question the end result: 
    shared caching between the framework and the ORM - and no need for shared 
    interfaces, nor any need to sacrifice features within the framework or the 
    ORM.
</p>

<h2>Sharing is good, developing solutions is better</h2>

<p>
    I think the core idea of the php-fig group is sound: <em>let's all start thinking
    about how we can make it easier to operate with each other</em>. That said, my 
    thoughts on how to accomplish that goal have changed significantly, and 
    boil down to:
</p>

<ul>
    <li>Use naming conventions that will reduce collisions (i.e., use 
        per-project vendor prefixes/namespaces)</li>
    <li>Use semantic versioning</li>
    <li>Keep your installation packages segregated</li>
    <li>Have a simple, discoverable way to autoload</li>
    <li>Provide interfaces for anything that could benefit from alternate implementations</li>
    <li>Don't write code that has side-effects in the global namespace 
        (including altering PHP settings or superglobals)</li>
</ul>

<p>
    Following these principals, you can play nice with each other, while still 
    fostering innovative and differentiating solutions to shared problems.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>PHP Master Series on Day Camp For Developers</title>
      <pubDate>Tue, 18 Dec 2012 20:24:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-18-php-master-series.html</link>
      <guid>http://mwop.net/blog/2012-12-18-php-master-series.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    <a href="http://blog.calevans.com">Cal Evans</a> has organized another 
    DayCamp4Developers event, this time entitled "<a 
    href="http://blog.calevans.com/2012/11/19/php-master-series-vol-1">PHP 
    Master Series, Volume 1</a>". I'm honored to be an invited speaker for this 
    first edition, where I'll be presenting my talk, "Designing Beautiful Software".
</p>

<p>
    Why would you want to participate? Well, for one, because you can interact directly
    with the various speakers during the presentations. Sure, you can likely find the slide
    decks elsewhere, or possibly even recordings. But if we all do our jobs right, we'll
    likely raise more questions than answers; if you attend, you'll get a chance to ask
    some of your questions immediately, <em>and we may even answer them!</em>
</p>

<p>
    On top of that, this is a fantastic lineup of speakers, and, frankly, not a lineup 
    I've ever participated in. In a typical conference, you'd likely see one or two of
    us, and be lucky if we weren't scheduled against each other; if you attend 
    this week, you'll get to see us all, back-to-back. 
</p>

<p>
    What else will you be doing this Friday, anyways, while <a 
    href="http://en.wikipedia.org/wiki/2012_phenomenon">you wait for the end of the 
    world?</a>
</p>

<p>
    So, do yourself a favor, and <a 
    href="http://phpmasterseriesv1.eventbrite.com/">register today</a>!
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>My ZendCon Beautiful Software Talk</title>
      <pubDate>Sat, 17 Nov 2012 13:53:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-11-17-zendcon-beautiful-software.html</link>
      <guid>http://mwop.net/blog/2012-11-17-zendcon-beautiful-software.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    Once again, I spoke at <a href="http://www.zendcon.com/">ZendCon</a> 
    this year; in talking with <a href="http://twitter.com/chwenz">Christian Wenz</a>,
    we're pretty sure that the two of us and <a href="http://andigutmans.blogspot.com">Andi</a>
    are the only ones who have spoken at all eight events.
</p>

<p>
    Unusually for me, I did not speak on a Zend Framework topic, and had
    only one regular slot (I also co-presented a Design Patterns tutorial
    with my team). That slot, however, became one of my favorite talks I've
    delivered: "Designing Beautiful Software". I've given this talk a couple
    times before, but I completely rewrote it for this conference in order 
    to better convey my core message: beautiful software is maintainable
    and extensible; writing software is a craft.
</p>

<p>
    I discovered today that not only was it recorded, but it's been <a href="http://youtu.be/mQsQ6QZ4dGg">posted
    on YouTube</a>:
</p>

<iframe width="420" height="315" src="http://www.youtube.com/embed/mQsQ6QZ4dGg" frameborder="0" allowfullscreen></iframe><p>
    I've also <a href="/slides/2012-10-25-BeautifulSoftware/BeautifulSoftware.html">posted the slides</a>.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>Zend Server, ZF2, and Page Caching</title>
      <pubDate>Mon, 05 Nov 2012 21:25:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-11-05-zend-server-caching.html</link>
      <guid>http://mwop.net/blog/2012-11-05-zend-server-caching.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    Zend Server has a very cool
    <a href="http://www.youtube.com/watch_v=i2XXn2SA5zM.html" target="_blank">Page Caching feature</a>. Basically, you can provide
    URLs or URL regular expressions, and tell Zend Server to provide full-page
    caching of those pages. This can provide a tremendous performance boost, without
    needing to change anything in your application structure; simply enable it for a
    set of pages, and sit back and relax.
</p><p style="text-align: center;">
    <img 
        style="max-width: 100%; max-height: 100%;"
        src="/images/blog/2012-11-04-Server-CachingRule.png"
        alt="Zend Server Page Caching"
        title="Zend Server Page Caching" />
</p>

<p>
    However, this feature is not entirely straight-forward when using a framework
    that provides its own routing, such as ZF2. The reason is because it assumes by
    default that each match maps to a specific file on the filesystem, and prepares
    the caching based on the actual <em>file</em> it hits. What this means for ZF2 and other
    similar frameworks is that any page that matches will return the cached version
    for the <em>first</em> match that also matches the same <em>file</em> -- i.e., <code>index.php</code> in
    ZF2. That's every page the framework handles. As an example, if I match on <code>/article/\d+</code>, it matches
    this to the file <code>index.php</code>, and then any other match that resolves to
    <code>index.php</code> gets served that same page. Not handy.
</p>

<p>
    The good part is that there's a way around this.
</p>

<p>
    When creating or modifying a caching rule, simply look for the text, "Create a
    separate cached page for each value of:" and click the "Add Parameter" button.
    Select <code>_SERVER</code> from the dropdown, and type <code>[REQUEST_URI]</code> for the value. Once
    saved, each page that matches the pattern will be cached separately.
</p>

<p>
    <img 
        style="max-width: 100%; max-height: 100%;"
        src="/images/blog/2012-11-04-Server-Caching-Request.png"
        alt="Zend Server Page Caching by Request"
        title="Zend Server Page Caching by Request" />
</p>

<p>
    Note: the <code>_SERVER</code> key may vary based on what environment/OS you're deployed
    in. Additionally, it may differ based on how you define rewrite rules -- some
    frameworks and CMS systems will append to the query string, for instance, in
    which case you may want to select the "entire query string" parameter instead of
    <code>_SERVER</code>; the point is, there's likely a way for you to configure it.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
  </channel>
</rss>
