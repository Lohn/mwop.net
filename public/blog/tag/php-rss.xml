<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/">
  <channel>
    <title>Tag: php :: phly, boy, phly</title>
    <description>Tag: php :: phly, boy, phly</description>
    <pubDate>Wed, 26 Mar 2014 20:30:00 +0000</pubDate>
    <generator>Zend_Feed_Writer 2 (http://framework.zend.com)</generator>
    <link>http://mwop.net/blog/tag/php.html</link>
    <atom:link rel="self" type="application/rss+xml" href="http://mwop.net/blog/tag/php-rss.xml"/>
    <item>
      <title>Apigility: Using RPC with HAL</title>
      <pubDate>Wed, 26 Mar 2014 20:30:00 +0000</pubDate>
      <link>http://mwop.net/blog/2014-03-26-apigility-rpc-with-hal.html</link>
      <guid>http://mwop.net/blog/2014-03-26-apigility-rpc-with-hal.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    A few days ago, we <a href="http://bit.ly/ag-1-beta1">released our first beta of Apigility</a>.
    We've started our documentation effort now, and one question has arisen a few times that I
    want to address: How can you use Hypermedia Application Language (HAL) in RPC services?
</p><h2>HAL?</h2>

<p>
    <a href="http://tools.ietf.org/html/draft-kelly-json-hal-06">Hypermedia Application Language</a>
    is an IETF proposal for how to represent resources and their relations within APIs. Technically,
    it provides two mediatypes, <code>application/hal+json</code> and <code>application/hal+xml</code>;
    however, Apigility only provides the JSON variant.
</p>

<p>
    The important things to know about HAL are:
</p>

<ul>
    <li>
        <p>
            It provides a standard way of describing relational links. All relational
            links are under a <code>_links</code> property of the resource. That property
            is an object. Each property of that object is a link relation; the value of
            each link relation is an object (or array of such objects) describing the link
            that must minimally contain an <code>href</code> proerty. The link object
            itself can contain some additional metadata, such as a mediatype, a name
            (useful for differentiating between multiple link objects assigned to the same
            relation).
        </p>

        <p>
            While not required, the specification recommends resources contain a "self"
            relational link, indicating the canonical location for the resource. This
            is particularly useful when we consider embedding (the next topic).
        </p>

        <p>
            Sound hard? It's not:
        </p>

        <div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {
            "href": "/blog/2014-03-26-apigility-rpc-with-hal"
        }
    }
}
        </code></pre></div>
    </li>

    <li>
        <p>
            Besides link relations, HAL also provides a standard way of describing
            <em>embedded resources</em>. An embedded resource is any other resource
            you can address via your API, and, as such, would be structured as a HAL
            resource -- in other words, it would have a <code>_links</code> property
            with relational links. Essentially, any property of the resource you're
            returning that can itself be addressed via the URI must be <em>embedded</em>
            in the resource. This is done via the property <code>_embedded</code>.
        </p>

        <p>
            Like <code>_links</code>, <code>_embedded</code> is an object. Each key in the
            object is the local name by which the resource refers to the embedded resource.
            The value of such keys can either be HAL resources or <em>arrays</em> of HAL
            resources; in fact, this is how <em>collections</em> are represented in HAL!
        </p>

        <p>
            As examples:
        </p>

        <div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {
            "href": "/blog/2014-03-26-apigility-rpc-with-hal"
        }
    },
    "_embedded": {
        "author": {
            "_links": {
                "self": {
                    "href": "/blog/author/matthew"
                }
            },
            "id": "matthew",
            "name": "Matthew Weier O'Phinney",
            "url": "http://mwop.net"
        },
        "tags": [
            {
                "_links": {
                    "self": {
                        "href": "/blog/tag/php"
                    }
                },
                "id": "php"
            },
            {
                "_links": {
                    "self": {
                        "href": "/blog/tag/rest"
                    }
                },
                "id": "rest"
            }
        ]
    }
}
        </code></pre></div>

        <p>
            The example above shows two embedded resources. The first is the author;
            the second, a collection of tags. Note that <em>every</em> object
            under <code>_embedded</code> is a HAL object!
        </p>

        <p>
            You can go quite far with this -- you can also have embedded resources
            inside your embedded resources, arbitrarily deep.
        </p>
    </li>
</ul>

<h2>RPC?</h2>

<p>
    RPC stands for Remote Procedure Call, and, when describing a web API, is 
    usually used to describe a web service that publishes multiple method calls 
    at a single URI using only <code>POST</code>; XML-RPC and SOAP are the
    usual suspects.
</p>

<p>
    In Apigility, we use the term RPC in a much looser sense; we use it to describe
    one-off services: actions like "authenticate," or "notify," or "register" 
    would all make sense here. They are actions that usually only need to respond
    to a single HTTP method, and which may or may not describe a "thing", which
    is what we usually consider a "resource" when discussing REST terminology.
</p>

<p>
    That said: what if what we want to return from the RPC call <em>are</em> REST
    resources?
</p>

<h2>Returning HAL from RPC Services</h2>

<p>
    In order to return HAL from RPC services, we need to understand (a) how 
    Content Negotiation works, and (b) what needs to be returned in order for the
    HAL renderer to be able to create a representation.
</p>

<p>
    For purposes of this example, I'm positing a <code>RegisterController</code> as
    an RPC service that, on success, is returning a <code>User</code> object 
    that I want rendered as a HAL resource.
</p>

<p>
    The <a href="https://github.com/zfcampus/zf-content-negotiation">zf-content-negotiation</a>
    module takes care of content negotiation for Apigility. It introspects the <code>Accept</code>
    header in order to determine if we can return a representation, and then, if it can, will
    cast any <code>ZF\ContentNegotiation\ViewModel</code> returned from a controller to the
    appropriate view model for the representation. From there, a renderer will pick up the view
    model and do what needs to be done.
</p>

<p>
    So, the first thing we have to do is return <code>ZF\ContentNegotiation\ViewModel</code>
    instances from our controller.
</p>

<div class="example"><pre><code language="php">
use Zend\Mvc\Controller\AbstractActionController;
use ZF\ContentNegotiation\ViewModel;

class RegisterController extends AbstractActionController
{
    public function registerAction()
    {
        /* ... do some work ... get a user ... */
        return new ViewModel(array('user' => $user));
    }
}
</code></pre></div>

<p>
    The <a href="https://github.com/zfcampus/zf-hal">zf-hal</a> module in Apigility
    creates the actual HAL representations. <code>zf-hal</code> looks for a "payload" variable in
    the view model, and expects that value to be either a <code>ZF\Hal\Entity</code>
    (single item) or <code>ZF\Hal\Collection</code>. When creating an <code>Entity</code>
    object, you need the object being represented, as well as the identifier. 
    So, let's update our return value.
</p>

<div class="example"><pre><code language="php">
use Zend\Mvc\Controller\AbstractActionController;
use ZF\ContentNegotiation\ViewModel;
use ZF\Hal\Entity;

class RegisterController extends AbstractActionController
{
    public function registerAction()
    {
        /* ... do some work
         * ... get a $user
         * ... assume we have also now have an $id
         */
        return new ViewModel(array('payload' => array(
            'user' => new Entity($user, $id),
        )));
    }
}
</code></pre></div>

<p>
    <code>zf-hal</code> contains what's called a "metadata map". This is a map of classes to
    information on how <code>zf-hal</code> should render them: what route to use, what additional
    relational links to inject, how to serialize the object, what field represents
    the identifier, etc.
</p>

<p>
    In most cases, you will have likely already defined a REST service for the
    resource you want to return from the RPC service, in which case you will
    be done. However, if you want, you can go in and manually configure
    the metadata map in your API module's <code>config/module.config.php</code>
    file:
</p>

<div class="example"><pre><code language="php">
return array(
    /* ... */
    'zf-hal' => array(
        'metadata_map' => array(
            'User' => array(
                'route_name' => 'api.rest.user',
                'entity_identifier_name' => 'username',
                'route_identifier_name' => 'user_id',
                'hydrator' => 'Zend\Stdlib\Hydrator\ObjectProperty',
            ),
        ),
    ),
);
</code></pre></div>

<p>
    Finally, we need to make sure that the service is configured to actually return
    HAL. We can do this in the admin if we want. Find the "Content Negotiation" section
    of the admin, and the "Content Negotiation Selector" item, and set that to "HalJson";
    don't forget to save! Alternately, you can do this manually in the API module's 
    <code>config/module.config.php</code> file, under the <code>zf-content-negotiation</code>
    section:
</p>

<div class="example"><pre><code language="php">
return array(
    /* ... */
    'zf-content-negotiation' => array(
        'controllers' => array(
            /* ... */
            'RegisterController' => 'HalJson',
        ),
        /* ... */
    ),
);
</code></pre></div>

<p>
    Once your changes are complete, when you make a successful request to the URI
    for your "register" RPC service, you'll receive a HAL response pointing to the
    canonical URI for the user resource created!
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 3</title>
      <pubDate>Mon, 25 Feb 2013 12:29:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-25-restful-apis-with-zf2-part-3.html</link>
      <guid>http://mwop.net/blog/2013-02-25-restful-apis-with-zf2-part-3.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    In my <a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">previous</a> 
    <a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">posts</a>, I 
    covered basics of JSON hypermedia APIs using Hypermedia Application Language
    (HAL), and methods for reporting errors, including API-Problem and vnd.error.
</p>

<p>
    In this post, I'll be covering <em>documenting</em> your API -- techniques 
    you can use to indicate what HTTP operations are allowed, as well as convey 
    the full documentation on what endpoints are available, what they accept, 
    and what you can expect them to return.
</p>

<p>
    While I will continue covering general aspects of RESTful APIs in this 
    post, I will also finally introduce several ZF2-specific techniques.
</p><h2>Why Document?</h2>

<p>
    If you're asking this question, you've either never consumed software, or
    your software is perfect and self-documenting. I frankly don't believe 
    either one.
</p>

<p>
    In the case of APIs, those consuming the API need to know how to use it. 
</p>

<ul>
    <li>What endpoints are available? Which operations are available for each endpoint?</li>
    <li>What does each endpoint expect as a payload during the request?</li>
    <li>What can you expect as a payload in return?</li>
    <li>How will errors be communicated?</li>
</ul>

<p>
    While the promise of hypermedia APIs is that each response tells you the
    next steps available, you still, somewhere along the way, need more
    information - what payloads look like, which HTTP verbs should be used,
    and more. If you're <strong>not</strong> documenting your API, you're
    "doing it wrong."
</p>

<h2>Where Should Documentation Live?</h2>

<p>
    This is the much bigger question.
</p>

<p>
    Of the questions I raised above, detailing what should be documented, there
    are two specific types. When discussing what operations are available, 
    we have a technical solution in the form of the <code>OPTIONS</code>
    method and its counterpart, the <code>Allow</code> header. Everything
    else falls under end-user documentation.
</p>

<h2>OPTIONS</h2>

<p>
    The HTTP specification details the <code>OPTIONS</code> method as 
    idempotent, non-cacheable, and for use in detailing what operations
    are available for the given resource specified by the request URI. It
    makes specific mention of the <code>Allow</code> header, but does not
    limit what is returned for requests made via this method.
</p>

<p>
    The <code>Allow</code> header details the allowed HTTP methods for the
    given resource.
</p>

<p>
    Used in combination, you make an <code>OPTIONS</code> request to a URI,
    and it should return a response containing an <code>Allow</code> header;
    from that header value, you then know what other HTTP methods can be made
    to that URI.
</p>

<p>
    What this tells us is that our RESTful endpoint should do the following:
</p>

<ul>
    <li>
        When an <code>OPTIONS</code> request is made, return a response with
        an <code>Allow</code> header that has a list of the available HTTP
        methods allowed.
    </li>

    <li>
        For any HTTP method we do <em>not</em> allow, we should return a
        "405 Not Allowed" response.
    </li>
</ul>

<p>
    These are fairly easy to accomplish in ZF2. <em>(See? I promised I'd
    get to some ZF2 code in this post!)</em>
</p>

<p>
    When creating RESTful endpoints in ZF2, I recommend using
    <code>Zend\Mvc\Controller\AbstractRestfulController</code>. This controller
    contains an <code>options()</code> method which you can use to respond to
    an <code>OPTIONS</code> request. As with any ZF2 controller, returning
    a response object will prevent rendering and bubble out immediately so
    that the response is returned.
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    public function options()
    {
        $response = $this->getResponse();
        $headers  = $response->getHeaders();

        // If you want to vary based on whether this is a collection or an
        // individual item in that collection, check if an identifier from
        // the route is present
        if ($this->params()->fromRoute('id', false)) {
            // Allow viewing, partial updating, replacement, and deletion
            // on individual items
            $headers->addHeaderLine('Allow', implode(',', array(
                'GET',
                'PATCH',
                'PUT',
                'DELETE',
            )));
            return $response;
        }

        // Allow only retrieval and creation on collections
        $headers->addHeaderLine('Allow', implode(',', array(
            'GET',
            'POST',
        )));
        return $response;
    }
}
</code></pre></div>

<p>
    The next trick is returning the 405 response if an invalid option is used.
    For this, you can create a listener in your controller, and wire it to 
    listen at higher-than-default priority. As an example:
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\EventManager\EventManagerInterface;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    protected $allowedCollectionMethods = array(
        'GET',
        'POST',
    );

    protected $allowedResourceMethods = array(
        'GET',
        'PATCH',
        'PUT',
        'DELETE',
    );

    public function setEventManager(EventManagerInterface $events)
    {
        parent::setEventManager($events);
        $events->attach('dispatch', array($this, 'checkOptions'), 10);
    }

    public function checkOptions($e)
    {
        $matches  = $e->getRouteMatch();
        $response = $e->getResponse();
        $request  = $e->getRequest();
        $method   = $request->getMethod();

        // test if we matched an individual resource, and then test
        // if we allow the particular request method
        if ($matches->getParam('id', false)) {
            if (!in_array($method, $this->allowedResourceMethods)) {
                $response->setStatusCode(405);
                return $response;
            }
            return;
        }

        // We matched a collection; test if we allow the particular request 
        // method
        if (!in_array($method, $this->allowedCollectionMethods)) {
            $response->setStatusCode(405);
            return $response;
        }
    }
}
</code></pre></div>

<p>
    Note that I moved the allowed methods into properties; if I did the above,
    I'd refactor the <code>options()</code> method to use those properties as
    well to ensure they are kept in sync.
</p>

<p>
    Also note that in the case of an invalid method, I return a response object.
    This ensures that nothing else needs to execute in the controller; I
    discover the problem and return early.
</p>

<h2>End-User Documentation</h2>

<p>
    Now that we have the technical solution out of the way, we're still left 
    with the bulk of the work left to accomplish: providing end-user 
    documentation detailing the various payloads, errors, etc.
</p>

<p>
    I've seen two compelling approaches to this problem. The first builds on
    the <code>OPTIONS</code> method, and the other uses a hypermedia link in
    every response to point to documentation.
</p>

<p>
    The <code>OPTIONS</code> solution is this: <a 
    href="http://zacstewart.com/2012/04/14/http-options-method.html">use the 
    body of an <code>OPTIONS</code> response to provide documentation</a>.
    (Keith Casey <a href="http://vimeo.com/49613738">gave an excellent short 
    presentation about this at REST Fest 2012</a>).
</p>

<p>
    The <code>OPTIONS</code> method allows for you to return a body in the
    response, and also allows for content negotiation. The theory, then, is
    that you return media-type-specific documentation that details the
    methods allowed, and what they specifically accept in the body. While
    there is no standard for this at this time, the first article I linked
    suggested including a description, the parameters expected, and one or more 
    example request bodies for each HTTP method allowed; you'd likely also
    want to detail the responses that can be expected.
</p>

<div class="example"><pre><code language="javascript">
{
    "POST": {
        "description": "Create a new status",
        "parameters": {
            "type": {
                "type": "string",
                "description": "Status type -- text, image, or url; defaults to text",
                "required": false
            },
            "text": {
                "type": "string",
                "description": "Status text; required for text types, optional for others",
                "required": false
            },
            "image_url": {
                "type": "string",
                "description": "URL of image for image types; required for image types",
                "required": false
            },
            "link_url": {
                "type": "string",
                "description": "URL of image for link types; required for link types",
                "required": false
            }
        },
        "responses": [
            {
                "describedBy": "http://example.com/problems/invalid-status",
                "title": "Submitted status was invalid",
                "detail": "Missing text field required for text type"
            },
            {
                "id": "abcdef123456",
                "type": "text",
                "text": "This is a status update",
                "timestamp": "2013-02-22T10:06:05+0:00"
            }
        ],
        "examples": [
            {
                "text": "This is a status update"
            },
            {
                "type": "image",
                "text": "This is the image caption",
                "image_url": "http://example.com/favicon.ico"
            },
            {
                "type": "link",
                "text": "This is a description of the link",
                "link_url": "http://example.com/"
            },
        ]
    }
}
</code></pre></div>

<p>
    If you were to use this methodology, you would alter the 
    <code>options()</code> method such that it does not return a response
    object, but instead return a view model with the documentation.
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    protected $viewModelMap = array(/* ... */);

    public function options()
    {
        $response = $this->getResponse();
        $headers  = $response->getHeaders();

        // Get a view model based on Accept types
        $model    = $this->acceptableViewModelSelector($this->viewModelMap);

        // If you want to vary based on whether this is a collection or an
        // individual item in that collection, check if an identifier from
        // the route is present
        if ($this->params()->fromRoute('id', false)) {
            // Still set the Allow header
            $headers->addHeaderLine('Allow', implode(
                ',', 
                $this->allowedResourceMethods
            ));

            // Set documentation specification as variables
            $model->setVariables($this->getResourceDocumentationSpec());
            return $model;
        }

        // Allow only retrieval and creation on collections
        $headers->addHeaderLine('Allow', implode(
            ',',
            $this->allowedCollectionMethods
        ));
        $model->setVariables($this->getCollectionDocumentationSpec());
        return $model;
    }
}
</code></pre></div>

<p>
    I purposely didn't provide the implementations of the 
    <code>getResourceDocumentationSpec()</code> and 
    <code>getCollectionDocumentationSpec()</code> methods, as that will likely
    be highly specific to your application. Another possibility is to use
    your view engine for this, and specify a template file that has the
    fully-populated information. This would require a custom renderer when
    using JSON or XML, but is a pretty easy solution.
</p>

<p>
    <strong>However, there's one cautionary tale to tell</strong>, something I 
    already mentioned: <code>OPTIONS</code>, per the specification, is 
    <em>non-cacheable</em>.  What this means is that everytime somebody makes an 
    <code>OPTIONS</code> request, any cache control headers you provide will be 
    ignored, which means hitting the server for each and every request to the 
    documentation.  Considering documentation is static, this is problematic; 
    it has even prompted <a href="http://www.mnot.net/blog/2012/10/29/NO_OPTIONS">blog 
    posts urging you not to use OPTIONS for documentation</a>.
</p>

<p>
    Which brings us to the second solution for end-user documentation: a static
    page referenced via a hypermedia link.
</p>

<p>
    This solution is insanely easy: you simply provide a <code>Link</code>
    header in your response, and provide a <code>describedby</code> reference
    pointing to the documentation page:
</p>

<div class="example"><pre><code language="http">
Link: &lt;http://example.com/api/documentation.md&gt;; rel="describedby"
</code></pre></div>

<p>
    With ZF2, this is trivially easy to accomplish: create a route and endpoint
    for your documentation, and then a listener on your controller that adds
    the <code>Link</code> header to your response.
</p>

<p>
    The latter, adding the link header, might look like this:
</p>

<div class="example"><pre><code language="php">
namespace My\Controller;
use Zend\EventManager\EventManagerInterface;
use Zend\Mvc\Controller\AbstractRestfulController;

class FooController extends AbstractRestfulController
{
    public function setEventManager(EventManagerInterface $events)
    {
        parent::setEventManager($events);
        $events->attach('dispatch', array($this, 'injectLinkHeader'), 20);
    }

    public function injectLinkHeader($e)
    {
        $response = $e->getResponse();
        $headers  = $response->getHeaders();
        $headers->addHeaderLine('Link', sprintf(
            '<%s>; rel="describedby"', 
            $this->url('documentation-route-name')
        ));
    }
}
</code></pre></div>

<p>
    If you want to ensure you get a fully qualified URL that includes the 
    schema, hostname, and port, there are a number of ways to do that as
    well; the above gives you the basic idea.
</p>

<p>
    Now, for the route and endpoint, there are tools that will help you
    simplify that task as well, in the form of a couple of ZF2 modules:
    <a href="https://github.com/weierophinney/PhlySimplePage">PhlySimplePage</a>
    and <a href="https://github.com/Soflomo/Prototype">Soflomo\Prototype</a>.
    <em>(Disclosure: I'm the author of PhlySimplePage.)</em>
</p>

<p>
    Both essentially allow you to specify a route and the corresponding
    template name to use, which means all you need to do is provide a little
    configuration, and a view template. <code>Soflomo\Prototype</code> has
    slightly simpler configuration, so I'll demonstrate it here:
</p>

<div class="example"><pre><code language="php">
return array(
    'soflomo_prototype' => array(
        'documentation-route-name' => array(
            'route'    => '/api/documentation',
            'template' => 'api/documentation',
        ),
    ),
    'view_manager' => array(
        'template_map' => array(
            'api/documentation' => __DIR__ . '/../view/api/documentation.phtml',
        ),
    ),
);
</code></pre></div>

<p>
    I personally have been using the <code>Link</code> header solution, as it's
    so simple to implement. It does <em>not</em> write the documentation for you,
    but thinking about it early and implementing it helps ensure you at least
    start writing the documentation, and, if you open source your project,
    you may find you have users who will write the documentation for you if
    they know where it lives.
</p>

<h2>Conclusions</h2>

<p>
    Document your API, or either nobody will use it, or all you're hear are
    complaints from your users about having to guess constantly about how to
    use it. Include the following information:
</p>

<ul>
    <li>What endpoint(s) is (are) available.</li>
    <li>Which operations are available for each endpoint.
        <ul>
            <li>What payloads are expected by the endpoint.</li>
            <li>What payloads can a user expect in return.</li>
            <li>What media types may be used for requests.</li>
            <li>What media types may be expected in responses.</li>
        </ul>
    </li>
</ul>

<p>
    Additionally, make sure that you do the <code>OPTIONS</code>/<code>Allow</code>
    dance; don't just accept any request method, and report the standard
    405 response for methods that you will not allow. Make sure you differentiate
    these for collections versus individual resources, as you likely may
    allow replacing or updating an individual resource, but likely will not
    want to do the same for a whole collection!
</p>

<h2>Next time</h2>

<p>
    So far, I've covered the basics of RESTful JSON APIS, specifically 
    recommending Hypermedia Application Language (HAL) for providing hypermedia
    linking and relations. I've covered error reporting, and provided two
    potential formats (API-Problem and vnd.error) for use with your APIs.
    Now, in this article, I've shown a bit about documenting your API both
    for machine consumption as well as end-users. What's left?
</p>

<p>
    In upcoming parts, I'll talk about ZF2's <code>AbstractRestfulController</code>
    in more detail, as well as how to perform some basic content negotiation.
    I've also had requests about how one might deal with API versioning, and will
    attempt to demonstrate some techniques for doing that as well. Finally,
    expect to see a post showing how I've tied all of this together in a 
    general-purpose ZF2 module so that you can ignore all of these posts and simply
    start writing APIs.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">Part 1</a></li>
    <li><a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">Part 2</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 2</title>
      <pubDate>Wed, 13 Feb 2013 13:40:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-13-restful-apis-with-zf2-part-2.html</link>
      <guid>http://mwop.net/blog/2013-02-13-restful-apis-with-zf2-part-2.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    In my <a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">last post</a>,
    I covered some background on REST and the Richardson Maturity Model, and some
    emerging standards around hypermedia APIs in JSON; in particular, I outlined
    aspects of Hypermedia Application Language (HAL), and how it can be used to
    define a generic structure for JSON resources.
</p>

<p>
    In this post, I cover an aspect of RESTful APIs that's often overlooked:
    reporting problems.
</p><h2>Background</h2>

<p>
    APIs are useful when they're working. But when they fail, they're only 
    useful if they provide us with meaningful information; if all I get is
    a status code, and no indication of what caused the issue, or where I might
    look for more information, I get frustrated.
</p>

<p>
    In consuming APIs, I've come to the following conclusions:
</p>

<ul>
    <li>
        Error conditions need to provide detailed information as to what went 
        wrong, and what steps I may be able to take next. An error code with
        no context gives me nothing to go on.
    </li>

    <li>
        Errors need to be reported consistently. Don't report the error one way
        one time, and another way the next.
    </li>

    <li>
        <strong>DO</strong> use HTTP status codes to indicate an error happened.
        Nothing is more irksome than getting back a 200 status with an error 
        payload.
    </li>

    <li>
        Errors should be reported in a format I have indicated I will Accept 
        (as in the HTTP header). Perhaps the only think more irksome than a 200
        status code for an error is getting back an HTML page when I expect 
        JSON.
    </li>
</ul>

<h2>Why Status Codes Aren't Enough</h2>

<p>
    Since REST leverages and builds on HTTP, an expedient solution for reporting
    problems is to simply use <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html">HTTP status codes</a>. 
    These are well understood by web developers, right?
</p>

<p>
    <code>4xx</code> error codes are errors made by the requestor, and are actually fairly 
    reasonable to use for reporting things such as lack of authorization tokens,
    incomplete requests, unsupportable operations, or non-supported media types.
</p>

<p>
    But what happens when the error is on the server - because something has
    gone wrong such as inability to reach your persistence layer or credential
    storage? The <code>5xx</code> series of status codes is sparse and wholly unsuited to
    reporting errors of these types -- <em>though you'll likely still want to use
    a <code>500</code> status to report the failure</em>. But what do you present to the consumer
    so that they know whether or not to try again, or what to report to you
    so that you can fix the issue?
</p>

<p>
    A status code simply isn't enough information most of the time. Yes, you 
    want to define standard status codes so that your clients can perform
    reasonable branching, but you also need a way to communicate <em>details</em>
    to the end-user, so that they can log the information for themselves, display
    information to their own end-users, and/or report it back to you so you can
    do something to resolve the situation.
</p>

<h2>Custom Media Types</h2>

<p>
    The first step is to use a custom media type. Media types are typically 
    both a name as well as a structure -- and the latter is what we're after
    when it comes to error reporting. 
</p>

<p>
    If we return a response using this media type, the client then knows how
    to parse it, and can then process it, log it, whatever.
</p>

<p>
    Sure, you can make up your own format -- as long as you are consistent
    in using it, and you document it. But personally, I don't like inventing
    new formats when standard formats exist already. Custom formats mean that 
    custom clients are required for working with the services; using a standard
    format can save effort and time.
</p>

<p>
    In the world of JSON, I've come across two error media types that appear to
    be gaining traction: <code>application/api-problem+json</code> and 
    <code>application/vnd.error+json</code>
</p>

<h3>API-Problem</h3>

<p>
    This particular media type is <a 
    href="http://tools.ietf.org/html/draft-nottingham-http-problem-02">via the 
    IETF</a>. Like HAL, it provides formats in both JSON and XML, making it 
    a nice cross-platform choice.
</p>

<p>
    As noted already, the media type is <code>application/api-problem+json</code>.
    The representation is a single resource, with the following properties:
</p>

<ul>
    <li>
        <strong>describedBy</strong>: a URL to a document describing the error condition (required)
    </li>

    <li>
        <strong>title</strong>: a brief title for the error condition (required)
    </li>

    <li>
        <strong>httpStatus</strong>: the HTTP status code for the current request (optional)
    </li>

    <li>
        <strong>detail</strong>: error details specific to this request (optional)
    </li>

    <li>
        <strong>supportId</strong>: a URL to the specific problem occurrence (e.g., to a log message) (optional)
    </li>
</ul>

<p>
    As an example:
</p>

<div class="example"><pre><code language="http">
HTTP/1.1 500 Internal Error
Content-Type: application/api-problem+json

{
    "describedBy": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html",
    "detail": "Status failed validation",
    "httpStatus": 500,
    "title": "Internal Server Error"
}
</code></pre></div>

<p>
    The specification allows a large amount of flexibility -- you can have your 
    own custom error types, so long as you have a description of them to link 
    to. You can provide as little or as much detail as you want, and even 
    decide what information to expose based on environment.
</p>

<p>
    I personally like to point to the HTTP status code definitions, and then 
    provide request-specific detail; I find this gives quick and simple results 
    that I can later shape as I add more detail to my API. However, the 
    specification definitely encourages you to have unique error types with 
    discrete URIs that describe them -- never a bad thing when creating APIs.
</p>

<h3>vnd.error</h3>

<p>
    This is a <a href="https://github.com/blongden/vnd.error">proposed media 
    type</a> within the HAL community. Like HAL, it provides formats in both 
    JSON and XML, making it a nice cross-platform choice.
</p>

<p>
    It differentiates from API-Problem in a few ways. First, it allows, and 
    even encourages, reporting collections of errors. If you consider PHP 
    exceptions and the fact that they support "previous" exceptions, this is a 
    powerful concept; you can report the entire chain of errors that led to the 
    response.  Second, it encourages pushing detail out of the web service; 
    errors include a "logRef" property that points to where the error detail lives. 
    This is probably better illustrated than explained.
</p>

<p>
    The response payload is an array of objects. Each object has the following 
    members:
</p>

<ul>
    <li>
        <strong>logRef</strong>: a unique identifier for the specific error which can then be
        used to identify the error within server-side logs (required)
    </li>

    <li>
        <strong>message</strong>: the error message itself (required)
    </li>

    <li>
        <strong>_links</strong>: HAL-compatible links. Typically, "help", "describes", and/or 
        "describedBy" relations will be defined here.
    </li>
</ul>

<p>
    As an example, let's consider the API-Problem example I had earlier, and
    provide a vnd.error equivalent:
</p>

<div class="example"><pre><code language="http">
HTTP/1.1 500 Internal Error
Content-Type: application/vnd.error+json

[
    {
        "logRef": "someSha1HashMostLikely",
        "message": "Status failed validation",
        "_links": {
            "describedBy": {"href": "http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html"}
        }
    }
]
</code></pre></div>

<p>
    vnd.error basically begs you to create custom error types, with documentation 
    end-points that detail the source of the error and what you can do about it 
    (this is true of API-Problem as well).
</p>

<p>
    The requirement to include a log reference ("logRef") and have it be unique 
    can be a stumbling block to implementation, however, as it requires effort 
    for uniquely identifying requests, and logging. However, both the 
    identification and logging can be automated.
</p>

<h2>Summary</h2>

<p>
    Error reporting in APIs is as important as the normal resource payloads 
    themselves. Without good error reporting, when an API raises errors, 
    clients have difficulty understanding what they can do next, and cannot
    provide you, the API provider, with information that will allow you to
    debug on the server side.
</p>

<p>
    As noted at the beginning of the article, if you follow the rules below,
    you'll make consumers of your API happier and more productive.
</p>

<ul>
    <li>
        <strong>DO</strong> use appropriate HTTP status codes to indicate an 
        error happened.
    </li>

    <li>
        Report errors in a format I have indicated I will Accept 
        (as in the HTTP header). 
    </li>
    <li>
        Report errors consistently. Don't report the error one way one time, 
        and another way the next. Standardize on a specific error-reporting 
        media type .  While you <em>can</em> create your own error structure, I 
        recommend using documented, accepted standards. This will make clients 
        more re-usable, and make many of your decisions for you.
    </li>

    <li>
        Provide detailed information as to what went wrong, and what steps I 
        may be able to take next. Provide documentation for each type of error, 
        and link to that documentation from your error payloads.
    </li>

</ul>

<p>
    Which brings me to...
</p>

<h2>Next time</h2>

<p>
    I realize I still haven't covered anything specific to ZF2, but I'll start 
    next time, when I cover the next topic: documenting your API. An 
    undocumented API is a useless API, so it's good to start baking 
    documentation in immediately. I'll survey some of the possibilities and how 
    they can be implemented in ZF2 in the next installment, and then we can get 
    our hands dirty with actual API development.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-11-restful-apis-with-zf2-part-1.html">Part 1</a></li>
    <li><a href="/blog/2013-02-25-restful-apis-with-zf2-part-3.html">Part 3</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>RESTful APIs with ZF2, Part 1</title>
      <pubDate>Wed, 13 Feb 2013 13:40:00 +0000</pubDate>
      <link>http://mwop.net/blog/2013-02-11-restful-apis-with-zf2-part-1.html</link>
      <guid>http://mwop.net/blog/2013-02-11-restful-apis-with-zf2-part-1.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    RESTful APIs have been an interest of mine for a couple of years, but due
    to <a href="http://framework.zend.com/blog//zend-framework-2-0-0-stable-released.html">circumstances</a>,
    I've not had much chance to work with them in any meaningful fashion until
    recently.
</p>

<p>
    <a href="http://akrabat.com/">Rob Allen</a> and I proposed a workshop for
    <a href="http://conference.phpbenelux.eu/2013/">PHP Benelux 2013</a> 
    covering RESTful APIs with ZF2. When it was accepted, it gave me the perfect
    opportunity to dive in and start putting the various pieces together.
</p><h2>Background</h2>

<p>
    I've attended any number of conference sessions on API design, read 
    countless articles, and engaged in quite a number of conversations. Three
    facts keep cropping up:
</p>

<ol>
    <li>JSON is fast becoming the preferred exchange format due to the ease 
    with which it de/serializes in almost every language.</li>
    <li>The "holy grail" is <a 
    href="http://martinfowler.com/articles/richardsonMaturityModel.html">Richardson 
    Maturity Model</a> Level 3.</li>
    <li>It's really hard to achieve RMM level 3 with JSON.</li>
</ol>

<h3>Richardson Maturity Model</h3>

<p>
    As a quick review, the Richardson Maturity Model has the following 4 levels:
</p>

<ul>
    <li>Level 0: "The swamp of POX." Basically, a service that uses TCP for 
        transport, primarily as a form of remote procedure call (RPC). 
        Typically, these are not really leveraging HTTP in any meaningful 
        fashion; most systems will use HTTP POST for all interactions. Also, 
        you will often have a single endpoint for all interactions, regardless 
        of whether or not they are strictly related. XML-RPC, SOAP, and 
        JSON-RPC fall under this category.
    </li>

    <li>Level 1: "Resources." In these services, you start breaking the service
        into multiple services, one per "resource," or, in object oriented terms,
        per object. This means a distinct URL per object, which means each
        has its own distinct identity on the web; this often extends not only 
        to the collection of objects, but to individual objects under the 
        collection as well (e.g., "/books" as well as "/books/life-of-pi"). The 
        service may still be RPC in nature, however, and, at this level, often 
        is still using a single HTTP method for all interactions with the 
        resource.
    </li>

    <li>Level 2: "HTTP Verbs." At this level, we start using HTTP verbs with
        our services in the way the HTTP specification intends. GET is for safe 
        operations, and should be cacheable; POST is used for creation and/or 
        updating; DELETE can be used to delete a resource; etc. Rather than 
        doing RPC style methods, we leverage HTTP, occasionally passing 
        additional parameters via the query string or request body.  
        Considerations such as HTTP caching and idempotence are taken into 
        account.
    </li>

    <li>Level 3: "Hypermedia Controls." Building on the previous level, our
        resource representations now also include <em>links</em>, which indicate
        what we can <em>do next</em>. At this level, our API becomes practically
        self-describing; given a single end-point, we should be able to start
        crawling it, using the links in a representation to lead us to the next
        actions.
    </li>
</ul>

<p>
    When I first started playing with web services around a decade ago, 
    everything was stuck at Level 0 or Level 1 -- usually with Level 1 users 
    downgrading to Level 0 because Level 0 offerred consistency and 
    predictability if you chose to use a service type that had a defined 
    envelope format (such as XML-RPC or SOAP).  (I even wrote the XML-RPC 
    server implementation for Zend Framework because I got sick of writing 
    one-off parsers/serializers for custom XML web service implementations.
    When you're implementing many services, predictability is a huge win.)
</p>

<p>
    A few years ago, I started seeing a trend towards Level 2. Web developers
    like the simplicity of using HTTP verbs, as they map very well to <a 
    href="http://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a>
    operations -- the bread and butter of web development. Couple this concept
    with JSON, and it becomes trivially simple to both create a web service, as
    well as consume it.
</p>

<p>
    <em>I'd argue that the majority of web developers are quite happy to be at 
    Level 2 -- and have no problem staying there. They're productive, and the 
    concepts are easy -- both to understand and to implement.</em>
</p>

<p>
    Level 3, though, is where it becomes really interesting. The idea that
    I can examine the represention <em>alone</em> in order to understand what
    I can do next is very intriguing and empowering.
</p>

<h3>JSON and Hypermedia</h3>

<p>
    With XML, hypermedia basically comes for free. Add some &lt;link&gt; 
    elements to your representation, and you're done -- and don't forget the 
    link <code>rel</code>ations!
</p>

<p>
    JSON, however, is another story.
</p>

<p>
    Where do the links go? <em>There is no single, defined way to represent a 
    hyperlink in JSON.</em>
</p>

<p>
    Fortunately, there are some emerging standards. 
</p>

<p>
    First is use of the <a href="http://www.w3.org/wiki/LinkHeader">"Link" HTTP 
    header</a>. While the page I linked shows only a single link in the
    header, you can have multiple links separated by commas. GitHub uses this
    when providing pagination links in their API. Critics will point out that
    the HTTP headers are not technically part of the representation, however;
    strict interpetations of REST and RMM indicate that the hypermedia links
    should be part of the resource representation. Regardless, having the links
    in the HTTP headers is useful for pre-traversal of a service, as you can
    perform HEAD requests only to discover possible actions and workflows.
</p>

<p>
    <a 
    href="http://amundsen.com/media-types/collection/format/">Collection+JSON</a>
    is interesting, as it describes the entire JSON envelope. My one criticism
    is that it details too much; whenever I see a format that dictates how to 
    describe types, I think of XML-RPC or SOAP, and get a little twitchy. It's
    definitely worth a look, though.
</p>

<p>
    What's captured my attention of late, however, is 
    <a href="http://stateless.co/hal_specification.html">Hypertext Application Language</a>,
    or HAL for short. HAL has very few rules, but succinctly describes both how
    to provide hypermedia in JSON as well as how to represent embedded resources
    - the two things that most need standardized structure in JSON. It does this
    while still providing a generic media type, and also describing a mirror 
    image XML format!
</p>

<h3>HAL Media Types</h3>

<p>
    HAL defines two generic media types: <code>application/hal+xml</code> and
    <code>application/hal+json</code>. You will use these as the response
    Content-Type, as they describe the response representation; the client
    can simply request <code>application/json</code>, and the response
    format remains compatible.
</p>

<h3>HAL and Links</h3>

<p>
    HAL provides a very simple structure for JSON hypermedia links. First, all 
    resource representations must contain hypermedia links, and all links are 
    provided in a "_links" object:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
    }
}
</code></pre></div>

<p>
    Second, links are properties of this object. The property name is the link
    relation, and the value is an object containing minimally an "href" 
    property.
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1234"}
    }
}
</code></pre></div>

<p>
    If a given relation can have multiple links, you provide instead an array
    of objects:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1234"},
        "conversation": [
            {"href": "http://example.com/api/status/1237"},
            {"href": "http://example.com/api/status/1241"}
        ]
    }
}
</code></pre></div>

<p>
    Individual links can contain other attributes as desired -- I've seen
    people include the relation again so that it's self-contained in the link 
    object, and it's not uncommon to include a title or name.
</p>

<h3>HAL and Resources</h3>

<p>
    HAL imposes no structure over resources other than requiring the hypermedia 
    links; even then, you typically do not include the hypermedia links when 
    making a request of the web service; the hypermedia links are included only 
    in the representations <em>returned</em> by the service.
</p>

<p>
    So, as an example, you would POST the following:
</p>

<div class="example"><pre><code language="http">
POST /api/status
Host: example.com
Accept: application/json
Content-Type: application/json

{
    "status": "This is my awesome status update!",
    "user": "mwop"
}
</code></pre></div>

<p>
    And from that request, you'd receive the following:
</p>

<div class="example"><pre><code language="http">
201 Created
Location: http://example.com/api/status/1347
Content-Type: application/hal+json

{
    "_links": {
        "self": {"href": "http://example.com/api/status/1347"}
    },
    "id": "1347",
    "timestamp": "2013-02-11 23:33:47",
    "status": "This is my awesome status update!",
    "user": "mwop"
}
</code></pre></div>

<h3>HAL and Embedded Resources</h3>

<p>
    The other important thing that HAL defines is how to <em>embed</em>
    resources. Why is this important? If the resource references other
    resources, you will want to be able to link to them so you can perform
    operations on them, too.
</p>

<p>
    Embedded resources are represented inside an "_embedded" object of the
    representation, and, as resources, contain their own "_links" object as 
    well. Each resource you embed is assigned to a property of that
    object, and if multiple objects of the same type are returned, an array
    of resources is assigned. In fact, this latter is how you represent
    <em>collections</em> in HAL.
</p>

<p>
    Let's consider a simple example first. In previous code samples, I have
    a "user" that's a string; let's make that an embedded resource instead.
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status/1347"}
    },
    "id": "1347",
    "timestamp": "2013-02-11 23:33:47",
    "status": "This is my awesome status update!",
    "_embedded": {
        "user": {
            "_links": {
                "self": {"href": "http://example.com/api/user/mwop"}
            }
            "id": "mwop",
            "name": "Matthew Weier O'Phinney",
            "url": "http://mwop.net"
        }
    }
}
</code></pre></div>

<p>
    I've moved the "user" out of the representation, and into the "_embedded"
    object -- because this is where you define embedded resources. Note that
    the "user" is a standard HAL resource itself -- containing hypermedia links.
</p>

<p>
    Now let's look at a collection:
</p>

<div class="example"><pre><code language="javascript">
{
    "_links": {
        "self": {"href": "http://example.com/api/status"},
        "next": {"href": "http://example.com/api/status?page=2"},
        "last": {"href": "http://example.com/api/status?page=100"}
    },
    "count": 2973,
    "per_page": 30,
    "page": 1,
    "_embedded": {
        "status": [
            {
                "_links": {
                    "self": {"href": "http://example.com/api/status/1347"}
                },
                "id": "1347",
                "timestamp": "2013-02-11 23:33:47",
                "status": "This is my awesome status update!",
                "_embedded": {
                    "user": {
                        "_links": {
                            "self": {"href": "http://example.com/api/user/mwop"}
                        }
                        "id": "mwop",
                        "name": "Matthew Weier O'Phinney",
                        "url": "http://mwop.net"
                    }
                }
            }
            /* ... */
        ]
    }
}
</code></pre></div>

<p>
    Note that the "status" property is an array; semantically, all resources
    under this key are of the same type. Also note that the parent resource
    has some additional link relations -- these are related to pagination, and
    allow a client to determine what the next and last pages are (and, if we 
    were midway into the collection, previous and first pages). Since the 
    collection is also a resource, it has some interesting metadata -- how
    many resources are in the collection, how many we represent per page, and
    what the current page is.
</p>

<p>
    Also note that you can nest resources -- simply include an "_embedded" 
    object inside an embedded resource, with additional resources, as I've
    done with the "user" resource inside the status resource shown here. It's 
    turtles all the way down.
</p>

<h2>Next Time</h2>

<p>
    The title of this post indicates I'll be talking about building RESTful 
    APIs with ZF2 -- but so far, I've not said anything about ZF2.
</p>

<p>
    I'll get there. But there's another detour to take: reporting errors.
</p>

<h3>Updates</h3>

<p>
    <em>Note: I'll update this post with links to the other posts in the series 
    as I publish them.</em>
</p>

<ul>
    <li><a href="/blog/2013-02-13-restful-apis-with-zf2-part-2.html">Part 2</a></li>
    <li><a href="/blog/2013-02-25-restful-apis-with-zf2-part-3.html">Part 3</a></li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>OpenShift, Cron, and Naked Domains</title>
      <pubDate>Sun, 30 Dec 2012 15:52:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-30-openshift-cron-and-naked-domains.html</link>
      <guid>http://mwop.net/blog/2012-12-30-openshift-cron-and-naked-domains.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    As an experiment, I migrated my website over to <a 
    href="http://openshift.redhat.com">OpenShift</a> yesterday. I've been hosting
    a pastebin there already, and have found the service to be both straightforward
    and flexible; it was time to put it to a more thorough test.
</p>

<p>
    In the process, I ran into a number of interesting issues, some of which took quite
    some time to resolve; this post is both to help inform other potential users of the
    service, as well as act as a reminder to myself.
</p><h2>Cron</h2>

<p>
    OpenShift offers a <a href="http://en.wikipedia.org/wiki/Cron">Cron</a> cartridge,
    which I was excited to try out.<sup><a href="#f1">1</a></sup>
</p>

<p>
    The basics are quite easy. In your repository's <code>.openshift</code> 
    directory is a <code>cron</code> subdirectory, further divided into 
    <code>minutely</code>, <code>hourly</code>, <code>daily</code>, <code>weekly</code>,
    and <code>monthly</code> subdirectories. You drop a script you want to run
    into one of these directories, and push your changes upstream.
</p>

<p>
    The problem is: what if I want a job to run at a specific time daily? or on 
    the quarter hour? or on a specific day of the week?
</p>

<p>
    As it turns out, you can manage all of the above, just not quite as succinctly as
    you would in a normal crontab. Here, for example, is a script that I run at 
    5AM daily; I placed it in the <code>hourly</code> directory so that it can test
    more frequently:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
if [ `date +%H` == "05" ]
then
    (
        export PHP=/usr/local/zend/bin/php ;
        cd $OPENSHIFT_REPO_DIR ; 
        $PHP public/index.php phlycomic fetch all ; 
        $PHP public/index.php phlysimplepage cache clear --page=pages/comics 
    )
fi
</code></pre></div>

<p>
    And here's one that runs on the quarter-hour, placed in the <code>minutely</code>
    directory:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
MINUTES=`date +%M`

for i in "00" "15" "30" "45";do
    if [ "$MINUTES" == "$i" ];then
        (
            export PHP=/usr/local/zend/bin/php ;
            cd $OPENSHIFT_REPO_DIR ;
            $PHP public/index.php githubfeed fetch 
        )
    fi
done
</code></pre></div>

<p>
    The point is that if you need more specificity, push the script into the 
    next more specific directory, and test against the time of execution.
</p>

<h2>Naked Domains</h2>

<p>
    Naked domains are domains without a preceding subdomain. In my case, this
    means "mwop.net", vs. "www.mwop.net".
</p>

<p>
    The problem that cloud hosting presents is that the IP address on which you
    are hosted can change at any time, for a variety of reasons. As such, you
    typically cannot use DNS A records to point to your domain; the recommendation
    is to use a CNAME record that points the domain to a "virtual" domain 
    registered with your cloud hosting provider.
</p>

<p>
    However, most domain registrars and DNS providers do not let you do this for
    a naked domain, particularly if you also have MX or other records associated
    with that naked domain.
</p>

<p>
    Some registrars will allow you to forward the A record to a subdomain. I tried
    this, but had limited success; I personally found that I ended up in an infinite
    loop situation when doing the DNS lookup.
</p>

<p>
    Another solution is to have a redirect in place for your naked domain to the
    subdomain, which can then be a CNAME record. Typically, this would require you
    have a web server under your control with a fixed IP that then simply redirects
    to the subdomain. Fortunately, there's an easier solution: <a 
    href="http://wwwizer.com/naked-domain-redirect">wwwizer</a>. You simply point
    your naked domain A record to the wwwizer IP address, and they will do a 
    redirect to your <code>www</code> subdomain.
</p>

<p>
    I implemented wwwizer on my domain (which is why you'll see "www.mwop.net" in
    your location bar), and it's been working flawlessly since doing so.
</p>

<h4>Private repositories</h4>

<p>
    I keep my critical site settings in a private repository, which allows me 
    to version them while keeping the credentials they hold out of the public eye.
    This means, however, that I need to use <a href="https://help.github.com/articles/managing-deploy-keys">GitHub deploy keys</a> on my server
    in order to retrieve changes.
</p>

<p>
    This was simple enough: I created an <code>ssh</code> subdirectory in my
    <code>$OPENSHIFT_DATA_DIR</code> directory, and generated a new SSH keypair.
</p>

<p>
    The problem was telling SSH to <em>use</em> this key when fetching changes.
</p>

<p>
    The solution is to use a combination of <code>ssh-agent</code> and <code>ssh-add</code>,
    and it looks something like this:
</p>

<div class="example"><pre><code language="bash">
#!/bin/bash
ssh-agent `ssh-add $OPENSHIFT_DATA_DIR/ssh/github-key && (
    cd $OPENSHIFT_DATA_DIR/config ; 
    git fetch origin ; 
    git rebase origin/mwop.net.config
)`
</code></pre></div>

<p>
    After testing the above, I put this in a <code>pre_build</code> script in 
    my OpenShift configuration so that I can autoupdate my private 
    configuration on each build. However, I discovered a new problem: when
    a build is being done, the <code>ssh-agent</code> is not available, which
    means the above cannot be executed. I'm still trying to find a solution.
</p>

<h2>Fin</h2>

<p>
    I'm pretty happy with the move. I don't have to do anything special
    to automate deployment, and all my cronjobs and deployment scripts are now
    self-contained in the repository, which makes my site more portable.
    While a few things could use more documentation, all the pieces are there
    and discoverable with a small amount of work.
</p>

<p>
    I'll likely give some other PaaS providers a try in the future, but for 
    the moment, I'm quite happy with the functionality and flexibility of 
    OpenShift.
</p>

<h4>Footnotes</h4>

<ul>
    <li id="f1">Zend Server's JobQueue can also be used as a cron replacement, 
    but I was not keen on exposing the job functionality via HTTP.</li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>On php-fig and Shared Interfaces</title>
      <pubDate>Thu, 20 Dec 2012 20:23:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-20-on-shared-interfaces.html</link>
      <guid>http://mwop.net/blog/2012-12-20-on-shared-interfaces.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    This is a post I've been meaning to write for a long time, and one requested
    of me personally by <a href="http://www.rooftopsolutions.nl/blog/">Evert 
    Pot</a> during the Dutch PHP Conference in June 2012. It details some observations
    I have of php-fig, and hopefully will serve as a record of why I'm not
    directly participating any longer.
</p>

<p>
    I was a founding member of the <a href="http://www.php-fig.org/">Framework 
    Interoperability Group</a>, now called "php-fig". I was one of around a dozen 
    folks who sat around a table in 2009 in Chicago during php|tek and started 
    discussions about what we could all do to make it possible to work better 
    together between our projects, and make it simpler for users to pick and choose 
    from our projects in order to build the solutions to their own problems.
</p>

<p>
    The first "standard" that came from this was <a 
    href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-0.md">PSR-0</a>, 
    which promoted a standard class naming convention that uses a 1:1 relationship 
    between the namespace and/or vendor prefix and the directory hierarchy, and the 
    class name and the filename in which it lives. To this day, there are both 
    those who hail this as a great step forward for cooperation, and simultaneously 
    others who feel it's a terrible practice. 
</p>

<p>
    And then nothing, for years. But a little over a year ago, there was a new 
    push by a number of folks wanting to do more. Paul Jones did a remarkable 
    job of spearheading the next <a href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-1-basic-coding-standard.md">two</a> 
    <a href="https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-2-coding-style-guide.md">standards</a>, 
    which centered around coding style. Again, just like with PSR-0, we had 
    both those feeling it was a huge step forward, and those who loathe the 
    direction.
</p>

<p>
    What was interesting, though, was that once we started seeing some new energy
    and momentum, it seemed that <em>everyone</em> wanted a say. And we started 
    getting dozens of folks a week asking to be voting members, and new proposal
    after new proposal. Whether or not somebody likes an existing standard, they
    want to have backing for a standard they propose.
</p>

<p>
    And this is when we started seeing proposals surface for shared interfaces, first
    around caching, and now around logging (though the latter is the first up for
    vote).
</p><h2>Shared Interfaces</h2>

<p>
    The idea around shared interfaces is simple: if we can come to a consensus on
    the basic interface for a common application task, libraries and frameworks
    can typehint on that shared interface, allowing developers to drop in the 
    implementation of their choosing -- or even a standard, reference implementation.
    The goal is to prevent Not Invented Here (NIH) syndrome, as well as to make
    it simpler to re-use components between one library and another. As an example,
    if you're using Framework A, and it has a caching library, and you're consuming
    ORM B, you'd be able to pass the same cache object to the ORM as you use in the
    framework.
</p>

<p>
    Great goals, really.
</p>

<p>
    But I'm not sure I buy into them.
</p>

<h2>Problems</h2>

<p>
    First, I agree that NIH is a problem.
</p>

<p>
    Second, I <em>also</em> think there's space for <em>multiple 
    implementations</em> of any given component. Often there are different 
    approaches that different authors will take: one might focus on 
    performance, another on having multiple adapters for providing different 
    capabilities, etc. Sometimes having a different background will present 
    different problem areas you want to resolve. As such, having multiple 
    implementations can be a very good thing; developers can look at what each 
    provides, and determine which solves the particular issues presented in the 
    current project.
</p>

<p>
    Because of this latter point, I have my reservations about shared interfaces.
</p>

<p>
    What if a particular approach requires deviating from the shared interface in 
    order to accomplish its goals? Additionally, in order to keep the greatest
    amount of compatibility between projects, shared interfaces tend to be so
    generic that specific implementations require developers to do a ton of manual
    type checking and munging of parameters, leading to more overhead, more difficulty
    testing and maintaining, and more difficulty documenting and understanding.
</p>

<p>
    As an example, consider the following (made up) signature for a log method:
</p>

<div class="example"><pre><code language="php">
public function log($message, array $context = null);
</code></pre></div>

<p>
    What if your library supports an idea of priorities? Where would that 
    information go in the above signature -- and would that differ between 
    libraries -- would one library use the key for a completely different 
    purpose? What about logging objects -- the signature doesn't say you can't, 
    but how would I know if a specific implementation supports it, and won't 
    blow up if I do pass one? Why must the <code>$context</code> be an array -- 
    why won't any <code>Traversable</code> or <code>ArrayAccess</code> object 
    work?
</p>

<p>
    Basically, by being overly generic, the signature becomes a liability for
    those implementing the interface; it prevents meaningful interoperability
    and leads to splintering implementations.
</p>

<p><em>
    (Please note: the above is completely fictional and has no bearing
    on current proposed or accepted standards. It is a thought exercise
    only.)
</em></p>

<p>
    Furthermore, if a given project writes their own implementation of a 
    component, and it has specialized features, why would they want to typehint
    on a generic, shared interface that doesn't implement those features? This
    would be counter-intuitive, as the project would then need to either check on
    additional interfaces for the specialized capabilities, duck-type, etc. --
    all of which make for more maintenance and code.
</p>

<p>
    In summary, my primary problem with the idea of shared interfaces is that I 
    feel there is always room for new thinking and ideas in any given problem 
    space, and that this thinking should not be restricted by what already 
    exists. Secondarily, I feel that it's okay for a given project to be 
    selective about what capabilities it requires for its internal consumption 
    and consistency, and should not limit itself to a standardized interface.
</p>

<h2>But, but, SHARING</h2>

<p>
    <em>Remember, the first point I made was that I think NIH is a 
    problem.</em> How do I reconcile that with a firm stance against shared 
    interfaces?
</p>

<p>
    Easy: <a href="http://en.wikipedia.org/wiki/Bridge_pattern">bridges</a> 
    and/or <a href="http://en.wikipedia.org/wiki/Adapter_pattern">adapters</a>.
</p>

<p>
    Let's go back to that example of Framework A, its caching library, and working
    with ORM B.
</p>

<p>
    Let's assume that ORM B defines an interface for caching, and let's say it
    looks like this:
</p>

<div class="example"><pre><code language="php">
interface CacheInterface
{
    public function set($key, $data);
    public function has($key);
    public function get($key);
}
</code></pre></div>

<p>
    Furthermore, we'll assume that the expected parameter values and return types
    are documented.
</p>

<p>
    What we as a consumer of both Framework A and ORM B can do is build an 
    <em>implementation</em> of <code>CacheInterface</code> that accepts a cache
    instance from Framework A, and proxies the various interface methods to that
    instance.
</p>

<div class="example"><pre><code language="php">
class FrameworkACache implements CacheInterface
{
    protected $cache;

    public function __construct(Cache $cache)
    {
        $this->cache = $cache;
    }

    public function set($key, $data)
    {
        $item = new CacheItem($key, $data);
        $this->cache->setItem($item);
    }

    public function has($key)
    {
        return $this->cache->exists($key);
    }

    public function get($key)
    {
        $item = $this->cache->getItem($key);
        return $item->getData();
    }
}
</code></pre></div>

<p>
    Assuming your code is well-decoupled, and you're using some sort of Inversion of
    Control container, you can likely create a factory for your ORM that will grab
    the above class, with the cache injected, and inject it into the ORM instance. 
    Yes, it's a bit more work, but it's difficult to question the end result: 
    shared caching between the framework and the ORM - and no need for shared 
    interfaces, nor any need to sacrifice features within the framework or the 
    ORM.
</p>

<h2>Sharing is good, developing solutions is better</h2>

<p>
    I think the core idea of the php-fig group is sound: <em>let's all start thinking
    about how we can make it easier to operate with each other</em>. That said, my 
    thoughts on how to accomplish that goal have changed significantly, and 
    boil down to:
</p>

<ul>
    <li>Use naming conventions that will reduce collisions (i.e., use 
        per-project vendor prefixes/namespaces)</li>
    <li>Use semantic versioning</li>
    <li>Keep your installation packages segregated</li>
    <li>Have a simple, discoverable way to autoload</li>
    <li>Provide interfaces for anything that could benefit from alternate implementations</li>
    <li>Don't write code that has side-effects in the global namespace 
        (including altering PHP settings or superglobals)</li>
</ul>

<p>
    Following these principals, you can play nice with each other, while still 
    fostering innovative and differentiating solutions to shared problems.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>PHP Master Series on Day Camp For Developers</title>
      <pubDate>Tue, 18 Dec 2012 20:24:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-12-18-php-master-series.html</link>
      <guid>http://mwop.net/blog/2012-12-18-php-master-series.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    <a href="http://blog.calevans.com">Cal Evans</a> has organized another 
    DayCamp4Developers event, this time entitled "<a 
    href="http://blog.calevans.com/2012/11/19/php-master-series-vol-1">PHP 
    Master Series, Volume 1</a>". I'm honored to be an invited speaker for this 
    first edition, where I'll be presenting my talk, "Designing Beautiful Software".
</p>

<p>
    Why would you want to participate? Well, for one, because you can interact directly
    with the various speakers during the presentations. Sure, you can likely find the slide
    decks elsewhere, or possibly even recordings. But if we all do our jobs right, we'll
    likely raise more questions than answers; if you attend, you'll get a chance to ask
    some of your questions immediately, <em>and we may even answer them!</em>
</p>

<p>
    On top of that, this is a fantastic lineup of speakers, and, frankly, not a lineup 
    I've ever participated in. In a typical conference, you'd likely see one or two of
    us, and be lucky if we weren't scheduled against each other; if you attend 
    this week, you'll get to see us all, back-to-back. 
</p>

<p>
    What else will you be doing this Friday, anyways, while <a 
    href="http://en.wikipedia.org/wiki/2012_phenomenon">you wait for the end of the 
    world?</a>
</p>

<p>
    So, do yourself a favor, and <a 
    href="http://phpmasterseriesv1.eventbrite.com/">register today</a>!
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>My ZendCon Beautiful Software Talk</title>
      <pubDate>Sat, 17 Nov 2012 13:53:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-11-17-zendcon-beautiful-software.html</link>
      <guid>http://mwop.net/blog/2012-11-17-zendcon-beautiful-software.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    Once again, I spoke at <a href="http://www.zendcon.com/">ZendCon</a> 
    this year; in talking with <a href="http://twitter.com/chwenz">Christian Wenz</a>,
    we're pretty sure that the two of us and <a href="http://andigutmans.blogspot.com">Andi</a>
    are the only ones who have spoken at all eight events.
</p>

<p>
    Unusually for me, I did not speak on a Zend Framework topic, and had
    only one regular slot (I also co-presented a Design Patterns tutorial
    with my team). That slot, however, became one of my favorite talks I've
    delivered: "Designing Beautiful Software". I've given this talk a couple
    times before, but I completely rewrote it for this conference in order 
    to better convey my core message: beautiful software is maintainable
    and extensible; writing software is a craft.
</p>

<p>
    I discovered today that not only was it recorded, but it's been <a href="http://youtu.be/mQsQ6QZ4dGg">posted
    on YouTube</a>:
</p>

<iframe width="420" height="315" src="http://www.youtube.com/embed/mQsQ6QZ4dGg" frameborder="0" allowfullscreen></iframe><p>
    I've also <a href="/slides/2012-10-25-BeautifulSoftware/BeautifulSoftware.html">posted the slides</a>.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>ZF2 Modules Quickstart (Screencast)</title>
      <pubDate>Wed, 19 Sep 2012 18:10:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-09-19-zf2-module-screencast.html</link>
      <guid>http://mwop.net/blog/2012-09-19-zf2-module-screencast.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
One of the exciting features of the newly released Zend Framework 2 is the new
module system.
</p>

<p>
While ZF1 had modules, they were difficult to manage. All resources for all
modules were initialized on each request, and bootstrapping modules was an
onerous task. Due to the difficulties, modules were never truly "plug-and-play",
and thus no ecosystem ever evolved for sharing modules.
</p>

<p>
In Zend Framework 2, we've architected the MVC from the ground up to make
modular applications as easy as possible. Within ZF2, the MVC simply cares about
events and services — and controllers are simply one kind of service. As such,
modules are primarily about telling the MVC about services and wiring event
listeners.
</p>

<p>
To give you an example, in this tutorial, I'll show you how to install the Zend
Framework 2 skeleton application, and we'll then install a module and see how
easy it is to add it to the application and then configure it.
</p><p>
To keep things simple, I'm using a unix-like environment. As such, if you are on
Windows, you may not have the same command-line tools available. If you are in
such a situation, perhaps try this inside a Linux virtual machine.
</p>

<iframe src="http://player.vimeo.com/video/49775540" 
width="500" height="281" frameborder="0" 
webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>
<p><a href="http://vimeo.com/49775540">Zend Framework 2 Module Quickstart</a></p>

<p>
Let's start by creating a new project. We'll execute a few commands to download
a skeleton application archive and extract it.
</p>

<div class="example"><pre><code language="bash">
% mkdir newproject
% cd newproject
% wget https://github.com/zendframework/ZendSkeletonApplication/tarball/master \
    -O ZendSkeletonApplication.tgz
% tar xzf ZendSkeletonApplication.tgz --strip-components=1
</code></pre></div>

<p>
    The Zend Framework skeleton application can be downloaded directly off of
    <a href="https://github.com">GitHub</a>. I'm showing using the download 
    from master, but you can also download a tarball or zipball for individual 
    tags as well. Because the download URL does not include an extension, I use 
    the <code>-O</code> switch to tell <code>wget</code> what filename to save to.
</p>

<p>
    <code>tar</code> has a nice option, `<code>--strip-components</code>`, which allows you to tell it to
    descend a certain number of levels deep into the archive when deflating. Since I
    know the tarball has a top-level directory named after the repository and a
    sha1, I'm simply telling <code>tar</code> to skip that and give me the contents of its
    child directory.
</p>

<p>
    At this point you have the skeleton application, but it has no dependencies 
    — not even Zend Framework itself! Let's rectify that situation. We'll use the
    dependency management tool <a href="https://getcomposer.org/">Composer</a> 
    to do this. We include the Composer phar file within the skeleton 
    application to make this fairly easy. Simply execute the following:
</p>

<div class="example"><pre><code language="bash">
% php composer.phar install
</code></pre></div>

<p>
    You may get a notice indicating that the composer version is older, and to 
    run "self-update"; you can ignore that for now.
</p>

<p>
    If all goes well, you should now have Zend Framework installed. Let's test 
    it out. I'm going to use the built-in web server in PHP 5.4 to demonstrate.
</p>

<div class="example"><pre><code language="bash">
% cd public
% php -S localhost:8080
</code></pre></div>

<p>
    If I browse to <code>http://localhost:8080</code> I should now see the 
    landing page for the skeleton application.
</p>

<img src="/images/screencasts/2012-09-19-zf2-module-screencast-01-zsa.png" style="width: 100%; height: 100%;" />

<p>
    Let's add a module to the application. Many sites require a contact form. 
    I've written one as a module some time ago, and called it <a 
    href="https://github.com/weierophinney/PhlyContact">PhlyContact</a>. To install
    it, I'll edit my project's <code>composer.json</code> and tell it about that 
    dependency:
</p>

<div class="example"><pre><code language="json">
{
    "require": {
        "php": "&gt;=5.3.3",
        "zendframework/zendframework": "dev-master",
        "phly/phly-contact": "dev-master"
    }
}
</code></pre></div>
    
<p>
    I know the name of the component from <a 
    href="http://packagist.org/">http://packagist.org/</a>, and I'm telling
    Composer that I want to use whatever the latest version is on its master 
    branch on GitHub. I happen to also know that PhlyContact requires a dev-master 
    version of Zend Framework, so I'll alter that dependency for now.
</p>

<p>
    Now, we need to tell composer to update our dependencies.
</p>

<div class="example"><pre><code language="bash">
% php composer.phar update
</code></pre></div>
    
<p>
    After executing the command, we should now see that it has installed; this 
    may take a little while.
</p>

<p>
    You need to inform the application about the module. This is so that we don't
    have to perform expensive file-system scanning operations, but also to make it
    explicit in your code what modules you're actually using. Enabling a module is
    usually as easy as adding an entry to <code>config\application.config.php</code>:
</p>

<div class="example"><pre><code language="php">
'modules' => array(
    'Application',
    'PhlyContact',
),
</code></pre></div>

<p>
    This particular module provides some reasonable defaults. In particular, it uses
    a CAPTCHA adapter that doesn't require additional configuration, and assumes
    that you will want to use the default <code>Sendmail</code> mail transport. As such, we can
    simply browse to it now. I happen to know that the module defines a <code>/contact</code>
    end point. Let's fire up our PHP web server again, and browse to that URL.
</p>

<div class="example"><pre><code language="bash">
% cd public
% php -S localhost:8080
</code></pre></div>

<img src="/images/screencasts/2012-09-19-zf2-module-screencast-02-contact.png" style="width: 100%; height: 100%;" />

<p>
    It just works!
</p>

<p>
    One philosophy we have for distributable modules in Zend Framework 2 is 
    that you should not need to touch the code in modules you install in your application.
    Instead, you should be able to configure and override behavior within the
    application configuration or in your application's site-specific modules. Let's
    alter the contact module to:
</p>

<ul>
    <li>first, change the URL it responds to, and</li>
    <li>second, use the "file" mail transport.</li>
</ul>

<p>
    Let's look at the default configuration. I'll browse to
    <code>vendor/phly/phly-contact/config/</code> and look at the <code>module.config.php</code> file.
</p>

<div class="example"><pre><code language="php">
return array(
    'phly_contact' => array(
        'captcha' => array(
            'class' => 'dumb',
        ),
        'form' => array(
            'name' => 'contact',
        ),
        'mail_transport' => array(
            'class' => 'Zend\Mail\Transport\Sendmail',
            'options' => array(
            )
        ),
        'message' => array(
            /*
            'to' => array(
                'EMAIL HERE' => 'NAME HERE',
            ),
            'sender' => array(
                'address' => 'EMAIL HERE',
                'name'    => 'NAME HERE',
            ),
            'from' => array(
                'EMAIL HERE' => 'NAME HERE',
            ),
             */
        ),
    ),

    /* ... */

    'router' => array(
        'routes' => array(
            'contact' => array(
                'type' => 'Literal',
                'options' => array(
                    'route' => '/contact',
                    'defaults' => array(
                        '__NAMESPACE__' => 'PhlyContact\Controller',
                        'controller'    => 'Contact',
                        'action'        => 'index',
                    ),
                ),
                'may_terminate' => true,
                'child_routes' => array(
                    'process' => array(
                        'type' => 'Literal',
                        'options' => array(
                            'route' => '/process',
                            'defaults' => array(
                                'action' => 'process',
                            ),
                        ),
                    ),
                    'thank-you' => array(
                        'type' => 'Literal',
                        'options' => array(
                            'route' => '/thank-you',
                            'defaults' => array(
                                'action' => 'thank-you',
                            ),
                        ),
                    ),
                ),
            ),
        ),
    ),
    /* ... */
);
</code></pre></div>

<p>
    Okay, that's interesting. I can define the captcha and options to use, the 
    name of the contact form, the mail transport I want to use, and even who the email 
    is sent from and who it goes to. In addition, it defines some routes.
</p>

<p>
    I'll create a new file, <code>config/autoload/phly-contact.local.php</code>. This is a
    local configuration file that will not be checked into my version control
    system. Now, let's add some configuration. First, I'll configure my mail
    transport.
</p>

<div class="example"><pre><code language="php">
return array(
    'phly_contact' => array(
        'mail_transport' => array(
            'class'   => 'Zend\Mail\Transport\File',
            'options' => array(
                'path' => 'data/mail/',
            ),
        ),
    ),
);
</code></pre></div>

<p>
    I'm telling the module to use the <code>File</code> mail transport, and telling the transport
    where I want messages written. By default, Zend Framework calls <code>chdir()</code> to
    change directory to the project root, so I can reference a directory relative to
    that. I'm simply going to write to a <code>data/mail/</code> directory. Let's create that,
    and make it world-writable for now to ensure the web server can write to it. (In
    production, you'd only want it writable by the web server user.)
</p>

<div class="example"><pre><code language="bash">
% mkdir -p data/mail
% chmod a+rwX data/mail
</code></pre></div>

<p>
    Now, let's change the base URL the contact form responds to; I want it to
    respond to <code>/contact-us</code>. Another principle of re-usable modules in ZF2 is that
    we recommend creating tree routes for each module, with the root of the tree
    being a literal route. This makes it easy to alter the base for routing, without
    needing to redefine all the routes in the module.
</p>

<p>
    I'll add the following to my local configuration, then. I'll simply override the
    parent route for my module, named "contact", and point it at a different URL.
</p>

<div class="example"><pre><code language="php">
'router' => array(
    'routes' => array(
        'contact' => array(
            'options' => array(
                'route' => '/contact-us',
            ),
        ),
    ),
),
</code></pre></div>

<p>
    Let's see if all this worked! Once again, I'll fire up PHP's built-in web
    server.
</p>

<div class="example"><pre><code language="bash">
% cd public
% php -S localhost:8080
</code></pre></div>

<p>
    Now, let's browse to <code>http://localhost:8080/contact-us</code> -- looks good! Just as an
    experiment, let's try the previously configured URL,
    <code>http://localhost:8080/contact</code>. We get a 404 now!
</p>

<img src="/images/screencasts/2012-09-19-zf2-module-screencast-03-config.png" style="width: 100%; height: 100%;" />
<img src="/images/screencasts/2012-09-19-zf2-module-screencast-04-404.png" style="width: 100%; height: 100%;" />

<p>
    Now, let's submit the form. I'll fill in some information; it's asking for my
    email address, a subject line, and a message, as well as for me to solve a
    simple CAPTCHA. Once I've done all that, I can send it.
</p>

<p>
    If all is well, we should now have a mail file in our data directory. Let's
    check.
</p>

<div class="example"><pre><code language="bash">
% ls -l data/mail/
</code></pre></div>

<p>
    And now let's look at it.
</p>

<div class="example"><pre><code language="bash">
% cat data/mail/ZendMail_1347989389_1009740165.tmp
Date: Tue, 18 Sep 2012 12:29:49 -0500
From: me@mwop.net
Reply-To: me@mwop.net
Subject: [Contact Form] Suspense!

Suspenseful, isn't it?
</code></pre></div>
    
<p>
    Looks good!
</p>

<p>
    Zend Framework 2 provides a wonderful modular architecture that will enable an
    ecosystem of 3rd party modules that should save you time and energy when
    developing your applications. I've demonstrated a simple one, a contact form,
    but many, many more already exist, and with a stable release now available, you
    should see that number grow. This is truly a wonderful step forward for
    developers, and I hope you find it as exciting as I do.
</p>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
    <item>
      <title>On Microframeworks</title>
      <pubDate>Fri, 17 Aug 2012 16:00:00 +0000</pubDate>
      <link>http://mwop.net/blog/2012-08-17-on-microframeworks.html</link>
      <guid>http://mwop.net/blog/2012-08-17-on-microframeworks.html</guid>
      <author>me@mwop.net (Matthew Weier O'Phinney)</author>
      <dc:creator>Matthew Weier O'Phinney</dc:creator>
      <content:encoded><![CDATA[<p>
    A number of months ago, <a href="http://funkatron.com/">Ed Finkler</a> 
    started a discussion in the PHP community about &#8220;<a 
    href="http://microphp.org/">MicroPHP</a>&#8221;; to summarize, the movement
    is about:
</p>

<ul>
    <li>Building small, single-purpose libraries.</li>
    <li>Using small things that work together to solve larger problems.</li>
</ul>

<p>
    I think there are some really good ideas that have come out of this, and 
    also a number of questionable practices<sup><a name="t1" href="#f1">1</a></sup>.
</p>

<p>
    One piece in particular I've focussed on is the concept of so-called 
    &#8220;microframeworks&#8221;.
</p><h2>What is a microframework?</h2>

<p>
    PHP has had microframeworks for quite some time<sup><a name="t2" href="#f2">2</a></sup>, 
    though I only really first saw the term being used around 3 years ago. The 
    &#8220;grand-daddy&#8221; of modern-day microframeworks can actually be 
    traced to Ruby, however, and specifically 
    <a href="http://www.sinatrarb.com">Sinatra</a>.
</p>

<p>
    Sinatra is not so much a framework as it is a domain-specific language (DSL).
    The language and structure it created, however, have been re-created in the
    vast majority of microframeworks you see currently in the PHP arena. 
    Specifically, it describes how to map HTTP request methods and paths to the
    code that will handle them. It borrowed route matching ideas from
    <a href="http://rubyonrails.org/">Ruby on Rails</a>, and relied on the fact 
    that Ruby uses the last value of a block as the return value.
</p>

<p>
    As some simple examples:
</p>

<div class="example"><pre><code language="ruby">
get '/hello/:name' do |n|
    "Hello #{n}!"
end

post '/address'
    # create address
end

put '/address/:id' |i|
    # update address
end

get '/feed.?:format?', :provides => ['rss', 'atom', 'xml'] do
    builder :feed
end
</code></pre></div>

<p>
    The language is expressive, and allows the developer to focus on two things:
</p>

<ul>
    <li>What are the specific entry points (URIs) for the application?</li>
    <li>What needs to be done for each specific entry point?</li>
</ul>

<p>
    I'd argue that the above two points are the defining characteristics of 
    modern microframeworks. Typically, the entry points are given the term
    &#8220;routing &#8221;, and the second corresponds to &#8220;controllers&#8221;.
</p>

<h2>PHP implementations</h2>

<p>
    I'd argue one of the earliest microframework implementations, though it 
    wasn't termed as such, was <a href="http://dev.horde.org/routes/">Horde 
    Routes</a><sup><a name="t3" href="#f3">3</a></sup> (which was itself inspired by <a 
    href="http://routes.readthedocs.org/en/latest/index.html">Python Routes</a>, 
    in turn inspired by the Rails routing system, like Sinatra). It follows
    the two principles I outlined above: it allows defining routes (entry points),
    and mapping them to controllers. Controllers for Routes are simply classes, 
    and a route must provide both a controller and an action in the match, with 
    the latter corresponding to a method on the controller class.
</p>

<p>
    Since around 2009, I've seen an increasing number of new PHP microframeworks<sup><a name="t4" href="#f4">4</a></sup>
    that follow in the steps of Sinatra and Horde. In the various 
    implementations I've looked at, instead of using a DSL, the authors have all
    opted for either a procedural or OOP interface. Starting with PHP 5.3, most
    authors have also primarily targetted any PHP callable as a controller, 
    favoring callbacks specifically. The fundamental ideas remain the same as 
    Sinatra, however:
</p>

<div class="example"><pre><code language="php">
/* Procedural */
get('/hello/:name', function ($n) {
    return "Hello {$n}!";
});

post('/address', function () {
    // create address
});

put('/address/:id' function ($i) {
    // update address
});

get('/feed.?:format?', function($feed, $format) {
    return builder($feed, $format);
});

/* OOP */
$app->get('/hello/:name', function ($n) {
    return "Hello {$n}!";
});

$app->post('/address', function () {
    // create address
});
end

$app->put('/address/:id', function ($i) {
    // update address
});

$app->get('/feed.?:format?', function ($feed, $format) use ($app) {
    return $app->builder($feed, $format);
})->constraints(['format' => '/^(rss|atom|xml)$/']);
</code></pre></div>

<p>
    One key difference I've witnessed in the implementations is surrounding
    how route matches are passed to the callback. In the examples above, they
    are passed as individual arguments to the handler. Some, however, opt for
    an approach more like Sinatra, which passes a single "params" argument into
    the scope of the handler. This approach tends to be more expedient both 
    from an implementation standpoint as well as a performance standpoint, as
    it does not require reflection to determine name and position of arguments,
    and makes handling wildcard arguments simpler. I've seen this latter 
    approach handled several ways:
</p>

<div class="example"><pre><code language="php">
// Pass in route match parameters as an argument.
$app->get('/feed.:format', function ($params) {
    $format = $params['format'];
});

// Pass in the $app instance, and retrieve route 
// match parameters from it.
$app->get('/feed.:format', function ($app) {
    $format = $app->params('format');
});

// Curry in the $app instance when desired, and 
// retrieve route match parameters from it.
$app->get('/feed.:format', function () use ($app) {
    $format = $app->params('format');
});
</code></pre></div>

<p>
    Another difference I've seen is in how route constraints, defaults, and
    names are handled. The most elegant solutions usually allow chaining
    method calls in order to alter this data:
</p>

<div class="example"><pre><code language="php">
$app->get('/feed.:format', function ($app) {
  })->constraints(['format' => '/^(atom|xml|json)$/'])
    ->name('feed');
</code></pre></div>

<p>
    One common feature I've seen is the ability to generate URLs based on the 
    defined routes. Most commonly, this is a function or method 
    <code>urlTo()</code>, which takes a route name, and an associative array
    of replacements.
</p>

<div class="example"><pre><code language="php">
echo $app->urlTo('feed', ['format' => 'atom']);
</code></pre></div>

<p>
    That's it in a nutshell: the ability to match HTTP request methods and
    path information, and map it to controllers/handlers, and to generate
    URLs based on those present in the application.
</p>

<h2>What are they good for?</h2>

<p>
    In my research and experience, microframeworks have three typical use cases:
</p>

<ol>
    <li>
        <b>Prototyping.</b> Because of their simplicity, microframeworks are 
        fantastic for prototyping a basic website. Very often, in the early
        stages of a site, you have a limited number of pages, and most often
        simply need to render a template with limited variable substitutions.
        Microframeworks are a perfect fit for this.
    </li>

    <li>
        <b>APIs</b>. API needs are usually quite well-defined, and often 
        involve a small, finite number of URLs. The logic required is usually
        already encapsulated in business objects, so the application layer
        is simply for filtering and returning a representation. Microframeworks
        again offer a nice fit.
    </li>

    <li>
        <b>Small, mostly static sites</b>. Similar to the first point, if you
        know the site will be relatively small and mostly static, then the
        minimal overhead of a microframework is often a good fit.
    </li>
</ol>

<h2>Where do microframeworks fail?</h2>

<p>
    Because of the rather declarative nature of microframeworks, and the
    typically 1:1 mapping of a route to a controller, microframeworks do
    not tend to promote code re-use. Additionally, this extends to how
    microframework applications are organized: usually, there are no clear
    guidelines on how to organize routes and controllers, much less separate
    them into multiple files. This can lead to maintenance issues as the
    application grows, as well as logistical issues whenever you need to 
    add new routes and controllers (do they go at the top, or bottom? are
    there other routes that could potentially match as well? etc.). 
</p>

<p>
    Additionally, though many frameworks offer ways to alter the workflow
    of the application either via hooks, events, or &#8220;middleware&#8221;<sup><a name="t5" href="#f5">5</a></sup>,
    most of these are limited in scope, often non-reusable, and often
    non-stackable. As such, comprehensive manipulation of the application
    workflow is out of reach.
</p>

<p>
    One other area that is overlooked, however, is one I find curious, 
    particularly in light of the MicroPHP movement: so much of the
    underlying plumbing is basically the same, yet every microframework
    re-implements it. Specifically:
</p>

<ul>
    <li>
        Routing is basically the same across most implementations, following the
        same basic specifications outlined in Rails. There are very few differences
        in the public APIs.
    </li>

    <li>
        Request and Response object abstraction is largely the same as well, 
        providing access to query/post/cookie/session/etc. parameters through
        roughly equivalent APIs.
    </li>

    <li>
        Many implement their own view layers.<sup><a name="t6" href="f6">6</a></sup>
    </li>
</ul>

<p>
    Most of this code should be considered commodity code at this point. There are 
    several outstanding view layers and templating engines available (Smarty, Twig,
    Savant, Zend\View). Standalone routing libraries exist such as Horde Routes,
    and even those bundled with frameworks are often available separately via
    Composer or Pyrus; the same is true with Request and Response object 
    abstraction. It seems to me that a few microframework authors should be 
    working on abstracting these concerns, and then focussing their efforts on
    differentiators in their own microframeworks.
</p>

<h2>An experiment</h2>

<p>
    Building on my last point, I looked at the APIs of <a 
    href="http://limonade-php.github.com/">Limonade</a> and <a 
    href="http://www.slimframework.com/">Slim Framework</a>, and built up a 
    specification for a microframework. I then matched as many pieces of it 
    as possible to existing components in <a 
    href="http://packages.zendframework.com/">ZF2</a>, and started building.
</p>

<p>
    In a matter of a few hours, I had written up a complete test suite<sup><a name="t7" href="#f7">7</a></sup> 
    and all code for a microframework, featuring the following (this is 
    basically the testdox output from the unit test suite):
</p>

<ul>
    <li>Lazy loads request</li>
    <li>Lazy loads response</li>
    <li>Request is injectible</li>
    <li>Response is injectible</li>
    <li>Halt should raise halt exception</li>
    <li>Response should contain status provided to halt</li>
    <li>Response should contain message provided to halt</li>
    <li>Stop should raise halt exception</li>
    <li>Response should remain unaltered after stop</li>
    <li>Redirect should raise halt exception</li>
    <li>Redirect should set 302 response status by default</li>
    <li>Redirect should set response status based on provided status code</li>
    <li>Redirect should set location header</li>
    <li>Map creates a segment route when provided with a string route</li>
    <li>Map can receive a route object</li>
    <li>Passing invalid route raises exception</li>
    <li>Map can receive a callable</li>
    <li>Passing invalid controller to route does not immediately raise exception</li>
    <li>Accessing invalid controller raises exception</li>
    <li>Passing invalid method to route via method raises exception</li>
    <li>Can set methods route responds to singly</li>
    <li>Can set methods route responds to as array</li>
    <li>Can set methods route responds to as multiple arguments</li>
    <li>Can specify additional method types to respond to</li>
    <li>Can specify route name</li>
    <li>Adding route using method type creates route that responds to that method type</li>
    <li>Running with no matching routes raises page not found exception</li>
    <li>Routing sets list of named routes</li>
    <li>Routing sets lists of routes by method</li>
    <li>Successful routing dispatches controller</li>
    <li>Unsuccessful routing triggers 404 event</li>
    <li>Calling halt triggers halt event</li>
    <li>Invalid controller triggers 501 event</li>
    <li>Exception raised in controller triggers 500 event</li>
    <li>Can pass to next matching route</li>
    <li>Url for helper assembles url based on name provided</li>
    <li>Url for helper assembles url based on name and params provided</li>
    <li>Url for helper assembles url based on current route match when no name provided</li>
    <li>Composes logger instance by default</li>
    <li>Can inject specific logger instance</li>
    <li>Mustache view is used by default</li>
    <li>Can inject alternate view instance</li>
    <li>Render renders a template to the response</li>
    <li>View model returns mustache view model by default</li>
    <li>Subsequent calls to view model return separate instances</li>
    <li>Can provide view model prototype</li>
</ul>

<p>
    I utilized ZF2's routing library from its MVC component, the request and response
    objects from its HTTP component, its Log component, and the Session component. These
    had a few other dependencies, but nothing terribly onerous.
</p>

<p>
    For the view, I used my own <a 
    href="http://weierophinney.github.com/phly_mustache">phly_mustache</a>, and provided
    a basic "view model" implementation that receives the application instance, thus
    allowing the ability to call application helpers (such as url generation).
</p>

<p>
    To make installation simple, I used <a href="http://getcomposer.org">Composer</a>
    to manage my dependencies on specific ZF2 components and for phly_mustache. The
    microframework contains only the code it needs to get its work done, leveraging
    the work of others whenever possible.
</p>

<p>
    This post is not meant as a way to announce a new microframework, however.<sup><a name="t8" href="#f8">8</a></sup>
    The point of the experiment was to prove something: microframeworks are
    trivially easy to write, <em>particularly if you follow the principals of 
    MicroPHP, and re-use existing code</em>. Just because code comes from a framework
    or a third-party library does not make it suspect or inferior; in fact,
    whenever possible, you should leverage such code so you can focus on 
    <em>writing awesome applications</em>.
</p>

<h2>Lessons learned</h2>

<p>
    I really like microframeworks for specific problems: prototyping, APIs, and 
    small, simple sites. I think they are ideally suited for these tasks. That
    said, I'd love to see some solid libraries targetting the fundamental, shared
    aspects of these efforts: routing, request and response abstraction, etc.
    With dependency management tools such as Composer and Pyrus, having required
    dependencies is not a big deal anymore, and re-use should be encouraged.
</p>

<p>
    Also, writing a microframework is an excellent coding exercise. It helps a 
    developer appreciate the complexities of abstraction while limiting the number
    of moving parts. I highly recommend it as an exercise -- but do it using 
    available components, and be prepared to throw it away and instead collaborate
    with others, or adopt something which better solves both the problems you have
    and the problems you anticipate.
</p>

<p>
    In sum: <em>Use the right tool for the job</em>. If you foresee expanding 
    requirements in your project's future, you may want to evaluate a full-stack
    framework,<sup><a name="t9" href="#f9">9</a></sup> or consider building something 
    robust that suits your specific project's needs. Use microframeworks where
    and when they make sense.
</p>

<h4>Afterword</h4>

<p>
    I'm well aware that Fabien Potencier has written
    <a href="http://fabien.potencier.org/article/50/create-your-own-framework-on-top-of-the-symfony2-components-part-1">a comprehensive series of posts on creating a microframework using Symfony 2
    components</a>. I deliberately chose not to read them until (a) ZF2 was 
    almost ready to release, and (b) I'd had a chance to formulate my own
    opinions on microframeworks. They're an excellent read, however, and show a 
    nice progression of development from flat PHP to a fully functional 
    microframework; click the link and see for yourself.
</p>

<h4>Footnotes</h4>

<ul>
    <li>
        <sup><a name="f1" href="#t1">1</a></sup> In particular, I feel that the movement 
        (a) disparages components from larger libraries simply because they
        originate from a larger library, and (b) distrust any code that has 
        additional dependencies. This latter I find truly puzzling, as I'd 
        think it fits the idea of &#8220;use small things that work together to 
        solve larger problems.&#8221; If the code solves a particular problem
        and allows you to focus on a larger problem, where it originates and 
        the number of dependencies should not be an issue.
    </li>

    <li>
        <sup><a name="f2" href="#t2">2</a></sup> In fact, my first foray into MVC in PHP 
        was writing a clone of Perl's <a href="http://cgi-app.org/">CGI::Application</a>,
        which in many ways is also a microframework.
    </li>

    <li>
        <sup><a name="f3" href="#t3">3</a></sup> Trivia: Both authors of Horde Routes 
        worked at Zend when I first started at the company, and Mike Naberezny
        wrote the very first lines of code for Zend Framework.
    </li>

    <li>
        <sup><a name="f4" href="#t4">4</a></sup> I swear, you see new ones on Github daily,
        and on <a href="http://phpdeveloper.org/">PHP Developer</a> at least
        once a week.
    </li>

    <li>
        <sup><a name="f5" href="#t5">5</a></sup> <a href="http://www.slimframework.com">Slim</a>
        has this concept. Basically, any callables placed between the route 
        string and the last callable when defining a route -- i.e., the &#8220;middle&#8221;
        arguments, and thus middleware -- will be executed in order prior to 
        attempting to execute the controller.
    </li>

    <li>
        <sup><a name="f6" href="#t6">6</a></sup> <a href="http://www.slimframework.com">Slim</a>
        is an outlier here, as it utilizes <a href="http://twig.sensiolabs.org/">Twig</a>
        by default.
    </li>

    <li>
        <sup><a name="f7" href="#t7">7</a></sup> I'm sure that my TDD experiment will warm the
        soul of <a href="http://www.littlehart.net/atthekeyboard/" alt="Chris 
        Hartjes">the Grumpy Programmer</a>.
    </li>

    <li>
        <sup><a name="f8" href="#t8">8</a></sup> That said, if you want to look at the results, 
        you can <a href="http://github.com/weierophinney/phlyty">find Phlyty on Github</a>.
    </li>

    <li>
        <sup><a name="f9" href="#t9">9</a></sup> As you may guess, I'm biased towards <a 
        href="http://framework.zend.com/">Zend Framework</a>. However, you should always
        carefully evaluate a framework against your project's needs.
    </li>
</ul>]]></content:encoded>
      <slash:comments>0</slash:comments>
    </item>
  </channel>
</rss>
